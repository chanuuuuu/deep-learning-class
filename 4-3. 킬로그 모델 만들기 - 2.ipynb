{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9781541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790f83db",
   "metadata": {},
   "source": [
    "## 5-1. 5차 학습 전 평가\n",
    "\n",
    "\n",
    "### 4차 학습 모델 \n",
    "\n",
    "- 기존 학습 방법들중 가장 성능이 좋은 모델 사용\n",
    "- VGG16보다 단순한 ResNet50을 전이학습을 진행하여 구현한 모델\n",
    "\n",
    "\n",
    "### 2차 데이터셋\n",
    "\n",
    "- kill 이미지 1261\n",
    "- non-kill 이미지 932\n",
    "\n",
    "\n",
    "### 5차 학습 전 평가 특징\n",
    "\n",
    "- 2차 데이터셋에서 ROI를 추출하여 평가 데이터로 사용합니다. \n",
    "- 2차 데이터셋 모두 사용하여 현재의 모델을 평가합니다. 추가된 데이터셋에 대한 정확도가 충분히 높다면 2차 데이터셋에 대한 학습이 필요하지 않기 때문입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "885bd5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADD_IMAGE_PATH = './dataset/kill_log_set_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f25f159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2193 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "add_train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    ADD_IMAGE_PATH,\n",
    "    label_mode = 'binary',\n",
    "    image_size = (540, 960),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79e121ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대충 본다.\n",
    "def crop_roi(image, label): \n",
    "    \n",
    "    cropped_image = tf.image.crop_to_bounding_box(\n",
    "        image, 10, 200, 190, 560\n",
    "    )\n",
    "    #resized_image = tf.image.resize(cropped_image, [190, 560], method = 'lanczos3')\n",
    "    #casted_image = resized_image / 255\n",
    "    return cropped_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5014404",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# ROI의 과정은 Data Augmentation의 수행이 아니므로 학습 데이터, 검증 데이터 모두 적용해야합니다.\n",
    "def make_crop_dataset(dataset):\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.map(crop_roi, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be4e5b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_cropped_dataset = make_crop_dataset(add_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "98e23e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_saved_model_t4 = tf.keras.models.load_model('./kill_log_models/model_t4.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b2a93676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 22s 311ms/step - loss: 0.1219 - accuracy: 0.9676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1219450831413269, 0.9676242470741272]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_saved_model_t4.evaluate(add_cropped_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5e7269",
   "metadata": {},
   "source": [
    "### 5차 학습전 평가의 결과\n",
    "\n",
    "\n",
    "- 평가 데이터의 정확도는 96.7%\n",
    "\n",
    "ROI를 추출하고, 추출된 이미지를 4차 학습 모델에 대해 평가한 결과, 기존의 98.7%에서 약 2%가 감소한 것을 확인할 수 있습니다. 2%의 감소는 2차 데이터셋에 대한 학습이 충분히 유의미할 수 있을 것으로 판단됩니다.\n",
    "\n",
    "현재 데이터가 학습과 평가 데이터가 구분되어있지 않습니다. 랜덤하게 추출하여 2차 데이터셋을 2차 데이터셋(학습용), 2차 테스트셋으로 분류합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f888b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import shutil\n",
    "SPLIT_VAL = 0.2\n",
    "\n",
    "ADD_TRAIN_PATH = './dataset/kill_log_dataset_2'\n",
    "ADD_TEST_PATH = './dataset/kill_log_testset_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9838c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(ADD_TRAIN_PATH):\n",
    "    os.mkdir(ADD_TRAIN_PATH)\n",
    "    \n",
    "if not os.path.exists(ADD_TEST_PATH):\n",
    "    os.mkdir(ADD_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bc813019",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1009\n",
      "746\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: './dataset/kill_log_dataset_2/.ipynb_checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-57b1b281c7ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_save_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mADD_TRAIN_PATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/.ipynb_checkpoints'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mADD_TEST_PATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/.ipynb_checkpoints'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[1;31m# can't continue even if onerror hook returns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_rmtree_unsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;31m# Allow introspection of whether or not the hardening against symlink\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    375\u001b[0m             \u001b[0mentries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscandir_it\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m         \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m         \u001b[0mentries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_rmtree_unsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscandir_it\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m             \u001b[0mentries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscandir_it\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: './dataset/kill_log_dataset_2/.ipynb_checkpoints'"
     ]
    }
   ],
   "source": [
    "for directory_name in os.listdir(ADD_IMAGE_PATH):\n",
    "    # kill_log, non_kill_log\n",
    "    directory_path = os.path.join(ADD_IMAGE_PATH, directory_name)\n",
    "    \n",
    "    # train_directory 생성\n",
    "    train_save_path = os.path.join(ADD_TRAIN_PATH, directory_name)\n",
    "    if not os.path.exists(train_save_path):\n",
    "        os.mkdir(train_save_path)\n",
    "    print(len(os.listdir(train_save_path)))\n",
    "    # test_directory 생성\n",
    "    test_save_path = os.path.join(ADD_TEST_PATH, directory_name)\n",
    "    if not os.path.exists(test_save_path):\n",
    "        os.mkdir(test_save_path)\n",
    "    \n",
    "    files = os.listdir(ADD_IMAGE_PATH + directory_name)\n",
    "    \n",
    "    # 전체 데이터 사이즈\n",
    "    data_size = len(files)\n",
    "    \n",
    "    # 테스트 데이터 사이즈\n",
    "    test_size = int(len(files) * 0.2)\n",
    "    \n",
    "    # 테스트 데이터로 선택되는 인덱스\n",
    "    test_data = np.random.choice(data_size, test_size, replace = False)\n",
    "    \n",
    "    for i, file in enumerate(files):\n",
    "        if i in test_data:\n",
    "            shutil.copy(os.path.join(directory_path, file), test_save_path)\n",
    "        else:\n",
    "            shutil.copy(os.path.join(directory_path, file), train_save_path)\n",
    "\n",
    "#shutil.rmtree(ADD_TRAIN_PATH + '/.ipynb_checkpoints')\n",
    "#shutil.rmtree(ADD_TEST_PATH + '/.ipynb_checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aba0ea90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1755 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "add_train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    ADD_TRAIN_PATH,\n",
    "    label_mode = 'binary',\n",
    "    image_size = (540, 960),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a194c68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 438 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "add_test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    ADD_TEST_PATH,\n",
    "    label_mode = 'binary',\n",
    "    image_size = (540, 960),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4577c3",
   "metadata": {},
   "source": [
    "## 5-2. 5차 학습 \n",
    "\n",
    "\n",
    "### ResNet\n",
    "\n",
    "- 4차 학습 모델 사용\n",
    "- VGG16보다 단순한 ResNet50사용\n",
    "\n",
    "\n",
    "### 1차 데이터셋 (기존 학습)\n",
    "\n",
    "- kill 이미지 786\n",
    "- non-kill 이미지 1832\n",
    "\n",
    "\n",
    "### 1차 테스트셋\n",
    "\n",
    "- kill 이미지 161\n",
    "- non-kill 이미지 149\n",
    "\n",
    "\n",
    "### 2차 데이터셋\n",
    "\n",
    "- kill 이미지 1009\n",
    "- non-kill 이미지 746\n",
    "\n",
    "\n",
    "### 2차 테스트셋\n",
    "\n",
    "- kill 이미지 252\n",
    "- non-kill 이미지 186\n",
    "\n",
    "\n",
    "### 5차 학습 특징\n",
    "\n",
    "- ROI를 수행합니다.\n",
    "- 2차 테스트 셋으로 4차 학습 모델을 평가합니다.\n",
    "- 그 후, 4차 학습 모델을 2차 데이터 셋으로 추가학습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b98acc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1755 files belonging to 2 classes.\n",
      "Using 1580 files for training.\n",
      "Found 1755 files belonging to 2 classes.\n",
      "Using 175 files for validation.\n"
     ]
    }
   ],
   "source": [
    "add_train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    ADD_TRAIN_PATH,\n",
    "    label_mode = 'binary',\n",
    "    image_size = (540, 960),\n",
    "    validation_split = 0.1,\n",
    "    seed = 6309,\n",
    "    subset = 'training'\n",
    ")\n",
    "\n",
    "add_val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    ADD_TRAIN_PATH,\n",
    "    label_mode = 'binary',\n",
    "    image_size = (540, 960),\n",
    "    validation_split = 0.1,\n",
    "    seed = 6309,\n",
    "    subset = 'validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39dc3218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 438 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "add_test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    ADD_TEST_PATH,\n",
    "    label_mode = 'binary',\n",
    "    image_size = (540, 960),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ac2518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_cropped_trainset = make_crop_dataset(add_train_dataset)\n",
    "add_cropped_valset = make_crop_dataset(add_val_dataset)\n",
    "add_cropped_testset = make_crop_dataset(add_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dca70896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model에 대한 체크포인트 생성 -> 가장 좋은 모델을 저장. (모델을 저장하는 것은 ) \n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"./kill_log_models/model_t5.hdf5\", monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "42a44812",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - 10s 200ms/step - loss: 0.1471 - accuracy: 0.9501 - val_loss: 0.1229 - val_accuracy: 0.9516\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.12289 to 0.12289, saving model to ./kill_log_models\\model_t5.hdf5\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 8s 187ms/step - loss: 0.0480 - accuracy: 0.9865 - val_loss: 0.0534 - val_accuracy: 0.9801\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12289 to 0.05337, saving model to ./kill_log_models\\model_t5.hdf5\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 8s 187ms/step - loss: 0.0291 - accuracy: 0.9943 - val_loss: 0.0382 - val_accuracy: 0.9858\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05337 to 0.03824, saving model to ./kill_log_models\\model_t5.hdf5\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 8s 187ms/step - loss: 0.0190 - accuracy: 0.9964 - val_loss: 0.0369 - val_accuracy: 0.9886\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03824 to 0.03690, saving model to ./kill_log_models\\model_t5.hdf5\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 8s 187ms/step - loss: 0.0133 - accuracy: 0.9993 - val_loss: 0.0373 - val_accuracy: 0.9886\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03690\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 8s 187ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9886\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03690\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 8s 187ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9858\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03690\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 8s 187ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9858\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.03690\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 8s 187ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9858\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03690\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 8s 188ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 0.9858\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03690 to 0.03659, saving model to ./kill_log_models\\model_t5.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a7ff10e748>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_model_t5 = tf.keras.models.load_model('./kill_log_models/model_t4.hdf5')\n",
    "func_model_t5.fit(add_cropped_trainset, validation_data = add_cropped_valset, callbacks = [checkpoint], epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bbf638a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 125ms/step - loss: 0.0880 - accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08803118765354156, 0.9771689772605896]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_model_t5.evaluate(add_cropped_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a61a8940",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_saved_model_t5 = tf.keras.models.load_model('./kill_log_models/model_t5.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f7183bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 111ms/step - loss: 0.0880 - accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08803118765354156, 0.9771689772605896]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_saved_model_t5.evaluate(add_cropped_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaafa35b",
   "metadata": {},
   "source": [
    "## 5-3. 1차 테스트 셋에 대한 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e5d593f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 310 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    './dataset/kill_log_testset/',\n",
    "    label_mode = 'binary',\n",
    "    image_size = (540, 960),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f49a2018",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_testset = make_crop_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fb362187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 110ms/step - loss: 0.0106 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01064381469041109, 1.0]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_saved_model_t5.evaluate(cropped_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ac6717",
   "metadata": {},
   "source": [
    "### 5차 학습 결과\n",
    "\n",
    "- 1차 평가 데이터의 정확도는 100%\n",
    "- 2차 평가 데이터의 정확도는 97.7%\n",
    "\n",
    "2차 평가 데이터에 대해서도 추가 학습 모델의 정확도가 매우 높은 것을 확인할 수 있습니다. 이전 학습에서 Data Augmentation을 통한 정확도 개선을 확인하였으므로 현재의 학습 방법에 Data Augmentation까지 추가하여 학습을 진행해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a1a151",
   "metadata": {},
   "source": [
    "## 6-1. 6차 학습\n",
    "\n",
    "\n",
    "### ResNet\n",
    "\n",
    "- 4차 학습 모델 사용\n",
    "- VGG16보다 단순한 ResNet50사용\n",
    "\n",
    "\n",
    "### 1차 데이터셋 (기존 학습)\n",
    "\n",
    "- kill 이미지 786\n",
    "- non-kill 이미지 1832\n",
    "\n",
    "\n",
    "### 1차 테스트셋\n",
    "\n",
    "- kill 이미지 161\n",
    "- non-kill 이미지 149\n",
    "\n",
    "\n",
    "### 2차 데이터셋\n",
    "\n",
    "- kill 이미지 1009\n",
    "- non-kill 이미지 746\n",
    "\n",
    "\n",
    "### 2차 테스트셋\n",
    "\n",
    "- kill 이미지 252\n",
    "- non-kill 이미지 186\n",
    "\n",
    "\n",
    "### 6차 학습 특징\n",
    "\n",
    "\n",
    "- 4차 학습 모델을 2차 데이터 셋으로 추가학습을 진행합니다.\n",
    "- ROI을 추출한 뒤 Data Augmentation을 통해 데이터셋의 크기를 늘립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d8b3cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2번 방식의 구현\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomZoom, RandomTranslation\n",
    "\n",
    "class AugmentationLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 가로 세로          \n",
    "        self.random_zoom = RandomZoom(0, (-0.4, 0), fill_mode = 'nearest')\n",
    "        self.random_trans = RandomTranslation(0.2, 0, fill_mode = 'nearest')\n",
    "    \n",
    "    def call(self, x, y):\n",
    "        x = self.random_zoom(x)\n",
    "        x = self.random_trans(x)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa43e4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번 방식의 구현을 함께 사용합니다. \n",
    "def random_brightness(image, label):\n",
    "    bright_changed_image = tf.image.random_brightness(image, 0.2, seed = 6309)\n",
    "    return bright_changed_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceff2961",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# map 함수를 통해 적용 -> Layer이기 때문에 모델과 함께 사용 가능.\n",
    "def make_augmented_dataset(dataset):\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.map(AugmentationLayer(), num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.map(random_brightness, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d19972d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation 적용\n",
    "add_cropped_trainset = make_crop_dataset(add_train_dataset)\n",
    "add_cropped_augmented_train_set = make_augmented_dataset(add_cropped_trainset)\n",
    "\n",
    "# validation, test set은 그대로 사용\n",
    "add_cropped_valset = make_crop_dataset(add_val_dataset)\n",
    "add_cropped_testset = make_crop_dataset(add_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "664143f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model에 대한 체크포인트 생성 -> 가장 좋은 모델을 저장. (모델을 저장하는 것은 ) \n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"./kill_log_models/model_t6.hdf5\", monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dbd27722",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 9s 140ms/step - loss: 0.1172 - accuracy: 0.9671 - val_loss: 0.1541 - val_accuracy: 0.9314\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15412, saving model to ./kill_log_models\\model_t6.hdf5\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 7s 131ms/step - loss: 0.0675 - accuracy: 0.9791 - val_loss: 0.0692 - val_accuracy: 0.9771\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15412 to 0.06924, saving model to ./kill_log_models\\model_t6.hdf5\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 7s 128ms/step - loss: 0.0480 - accuracy: 0.9880 - val_loss: 0.0561 - val_accuracy: 0.9886\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06924 to 0.05609, saving model to ./kill_log_models\\model_t6.hdf5\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 7s 129ms/step - loss: 0.0430 - accuracy: 0.9886 - val_loss: 0.0555 - val_accuracy: 0.9886\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.05609 to 0.05551, saving model to ./kill_log_models\\model_t6.hdf5\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 7s 130ms/step - loss: 0.0307 - accuracy: 0.9911 - val_loss: 0.0779 - val_accuracy: 0.9829\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05551\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 7s 128ms/step - loss: 0.0270 - accuracy: 0.9937 - val_loss: 0.0752 - val_accuracy: 0.9714\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05551\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 7s 129ms/step - loss: 0.0269 - accuracy: 0.9924 - val_loss: 0.0964 - val_accuracy: 0.9829\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05551\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 7s 131ms/step - loss: 0.0249 - accuracy: 0.9924 - val_loss: 0.0926 - val_accuracy: 0.9771\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05551\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 7s 131ms/step - loss: 0.0223 - accuracy: 0.9924 - val_loss: 0.1086 - val_accuracy: 0.9771\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05551\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 7s 130ms/step - loss: 0.0151 - accuracy: 0.9975 - val_loss: 0.0901 - val_accuracy: 0.9829\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a80bcfe3c8>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_model_t6 = tf.keras.models.load_model('./kill_log_models/model_t4.hdf5')\n",
    "func_model_t6.fit(add_cropped_augmented_train_set, validation_data = add_cropped_valset, callbacks = [checkpoint], epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bd5b0843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 110ms/step - loss: 0.0958 - accuracy: 0.9703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09581686556339264, 0.9703196287155151]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_model_t6.evaluate(add_cropped_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c732ea13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 110ms/step - loss: 0.0702 - accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07015789300203323, 0.9771689772605896]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_saved_model_t6 = tf.keras.models.load_model('./kill_log_models/model_t6.hdf5')\n",
    "func_saved_model_t6.evaluate(add_cropped_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "be662d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 108ms/step - loss: 0.0106 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01064381469041109, 1.0]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_saved_model_t5.evaluate(cropped_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b8d7d3",
   "metadata": {},
   "source": [
    "### 6차 학습의 결과\n",
    "\n",
    "- 학습 데이터의 가장 높은 정확도는 99%\n",
    "\n",
    "- 1차 평가 데이터의 정확도는 100%\n",
    "\n",
    "- 2차 평가 데이터의 정확도는 97.7%\n",
    "\n",
    "ROI 추출 및 Data Augmentation까지 추가하여 학습을 진행해보았으나, 5차 학습과의 정확도 차이가 발생하지 않았습니다. 이로 미루어볼 때, 2차 학습 데이터를 추가학습한 5차 모델은 Data Augmentation를 통해 생성되는 새로운 이미지들에 대해서도 충분히 예측가능하다는 것으로 생각해볼 수 있습니다. 여러가지 학습 방법으로 학습을 진행해보았습니다. 가장 좋은 모델인 6차 학습 모델에 대해서 파인튜닝을 통해 정확도를 향상시키도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05091893",
   "metadata": {},
   "source": [
    "## 6-2. 6차 학습에 대한 파인튜닝\n",
    "\n",
    "평가 데이터의 정확도가 충분히 높기 때문에 파인튜닝을 통해서 현재 모델을 고도화하는 방법을 선택할 수 있습니다.\n",
    "\n",
    "\n",
    "### ResNet\n",
    "\n",
    "- 6차 학습 모델 사용\n",
    "- VGG16보다 단순한 ResNet50사용\n",
    "\n",
    "\n",
    "### 1차 데이터셋 \n",
    "\n",
    "- kill 이미지 786\n",
    "- non-kill 이미지 1832\n",
    "\n",
    "\n",
    "### 1차 테스트셋\n",
    "\n",
    "- kill 이미지 161\n",
    "- non-kill 이미지 149\n",
    "\n",
    "\n",
    "### 2차 데이터셋\n",
    "\n",
    "- kill 이미지 1009\n",
    "- non-kill 이미지 746\n",
    "\n",
    "\n",
    "### 2차 테스트셋\n",
    "\n",
    "- kill 이미지 252\n",
    "- non-kill 이미지 186\n",
    "\n",
    "\n",
    "### 6차 파인튜닝 특징\n",
    "\n",
    "\n",
    "- 전이학습을 위해 가중치 갱신이 불가능하도록 설정한 것을 파인튜닝을 위해 가능하도록 설정합니다.\n",
    "- 1, 2차의 데이터셋을 결합합니다.\n",
    "- ROI을 추출한 뒤 Data Augmentation을 통해 데이터셋의 크기를 늘립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9a90e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_model_t62 = tf.keras.models.load_model('./kill_log_models/model_t6.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba892384",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, None, None, 6 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, None, None, 6 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, None, None, 2 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, None, None, 2 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, None, None, 2 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, None, None, 2 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, None, None, 5 0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, None, None, 5 0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, None, None, 5 0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, None, None, 5 0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, None, None, 5 0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, None, None, 1 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, None, None, 1 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, None, None, 1 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, None, None, 1 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, None, None, 1 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, None, None, 1 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, None, None, 1 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, None, None, 2 0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, None, None, 2 0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, None, None, 2 0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, None, None, 2 0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "func_model_t62.layers[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16bbd4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_model_t62.layers[1].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71260cbc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, None, None, 6 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, None, None, 6 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, None, None, 2 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, None, None, 2 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, None, None, 2 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, None, None, 2 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, None, None, 5 0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, None, None, 5 0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, None, None, 5 0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, None, None, 5 0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, None, None, 5 0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, None, None, 1 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, None, None, 1 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, None, None, 1 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, None, None, 1 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, None, None, 1 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, None, None, 1 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, None, None, 1 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, None, None, 2 0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, None, None, 2 0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, None, None, 2 0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, None, None, 2 0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Trainable params의 갯수가 증가한 것을 확인할 수 있다.\n",
    "func_model_t62.layers[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bbd9d69",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 190, 560, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                65568     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 23,653,441\n",
      "Trainable params: 23,600,257\n",
      "Non-trainable params: 53,184\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Trainable params의 갯수가 증가한 것을 확인할 수 있다.\n",
    "func_model_t62.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e6685e",
   "metadata": {},
   "source": [
    "### 데이터셋 구성하기\n",
    "\n",
    "- 1차 데이터셋 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5360ce9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2618 files belonging to 2 classes.\n",
      "Using 2357 files for training.\n",
      "Found 2618 files belonging to 2 classes.\n",
      "Using 261 files for validation.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_PATH = './dataset/kill_log_dataset'\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    IMAGE_PATH,\n",
    "    # label_mode 대신에 class_mode사용한다.\n",
    "    image_size = (540, 960),\n",
    "    label_mode = 'binary',\n",
    "    batch_size = 30,\n",
    "    seed = 6309,\n",
    "    validation_split = 0.1,\n",
    "    subset = 'training',\n",
    ")\n",
    "\n",
    "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    IMAGE_PATH,\n",
    "    # label_mode 대신에 class_mode사용한다.\n",
    "    image_size = (540, 960),\n",
    "    label_mode = 'binary',\n",
    "    batch_size = 30,\n",
    "    seed = 6309,\n",
    "    validation_split = 0.1,\n",
    "    subset = 'validation',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b7a1ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_trainset = make_crop_dataset(train_dataset)\n",
    "add_cropped_trainset = make_crop_dataset(add_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c30a749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_valset = make_crop_dataset(val_dataset)\n",
    "add_cropped_valset = make_crop_dataset(add_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c62ce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1, 2차 데이터셋이 결합된 데이터셋\n",
    "merged_trainset = cropped_trainset.concatenate(add_cropped_trainset).shuffle(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "236a3ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1, 2차 데이터셋이 결합된 데이터셋\n",
    "merged_valset = cropped_valset.concatenate(add_cropped_valset).shuffle(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bf69cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결합된 데이터셋에 Data Augmentation 추가\n",
    "merged_cropped_augmented_train_set = make_augmented_dataset(merged_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03960d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loss에 따른 빠른 종료 -> 빠른 구현을 위해서 선택적으로 적용할 수 있다.\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# model에 대한 체크포인트 생성 -> 가장 좋은 모델을 저장. (모델을 저장하는 것은 ) \n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"./kill_log_models/model_t62.hdf5\", monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79bd2831",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_model_t62.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),  # Low learning rate\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee8f19ec",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "129/129 [==============================] - 102s 478ms/step - loss: 0.0883 - accuracy: 0.9738 - val_loss: 0.0502 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05015, saving model to ./kill_log_models\\model_t62.hdf5\n",
      "Epoch 2/20\n",
      "129/129 [==============================] - 52s 401ms/step - loss: 0.0460 - accuracy: 0.9831 - val_loss: 0.0401 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05015 to 0.04014, saving model to ./kill_log_models\\model_t62.hdf5\n",
      "Epoch 3/20\n",
      "129/129 [==============================] - 53s 402ms/step - loss: 0.0270 - accuracy: 0.9931 - val_loss: 0.0601 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04014\n",
      "Epoch 4/20\n",
      "129/129 [==============================] - 53s 402ms/step - loss: 0.0294 - accuracy: 0.9914 - val_loss: 0.0342 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04014 to 0.03422, saving model to ./kill_log_models\\model_t62.hdf5\n",
      "Epoch 5/20\n",
      "129/129 [==============================] - 53s 402ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.0326 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.03422 to 0.03264, saving model to ./kill_log_models\\model_t62.hdf5\n",
      "Epoch 6/20\n",
      "129/129 [==============================] - 53s 403ms/step - loss: 0.0118 - accuracy: 0.9978 - val_loss: 0.0321 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.03264 to 0.03209, saving model to ./kill_log_models\\model_t62.hdf5\n",
      "Epoch 7/20\n",
      "129/129 [==============================] - 55s 422ms/step - loss: 0.0110 - accuracy: 0.9981 - val_loss: 0.0266 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.03209 to 0.02657, saving model to ./kill_log_models\\model_t62.hdf5\n",
      "Epoch 8/20\n",
      "129/129 [==============================] - 53s 403ms/step - loss: 0.0095 - accuracy: 0.9989 - val_loss: 0.0272 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02657\n",
      "Epoch 9/20\n",
      "129/129 [==============================] - 53s 404ms/step - loss: 0.0095 - accuracy: 0.9993 - val_loss: 0.0336 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02657\n",
      "Epoch 10/20\n",
      "129/129 [==============================] - 53s 404ms/step - loss: 0.0077 - accuracy: 0.9994 - val_loss: 0.0281 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02657\n",
      "Epoch 11/20\n",
      "129/129 [==============================] - 53s 403ms/step - loss: 0.0063 - accuracy: 0.9999 - val_loss: 0.0249 - val_accuracy: 0.9977\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02657 to 0.02485, saving model to ./kill_log_models\\model_t62.hdf5\n",
      "Epoch 12/20\n",
      "129/129 [==============================] - 53s 403ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.0343 - val_accuracy: 0.9908\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.02485\n",
      "Epoch 13/20\n",
      "129/129 [==============================] - 53s 403ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.02485\n",
      "Epoch 14/20\n",
      "129/129 [==============================] - 53s 403ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0365 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.02485\n",
      "Epoch 15/20\n",
      "129/129 [==============================] - 53s 404ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.0280 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.02485\n",
      "Epoch 16/20\n",
      "129/129 [==============================] - 53s 403ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.0321 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.02485\n",
      "Epoch 17/20\n",
      "129/129 [==============================] - 53s 404ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.0219 - val_accuracy: 0.9977\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.02485 to 0.02193, saving model to ./kill_log_models\\model_t62.hdf5\n",
      "Epoch 18/20\n",
      "129/129 [==============================] - 53s 403ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.0312 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.02193\n",
      "Epoch 19/20\n",
      "129/129 [==============================] - 53s 403ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 0.9977\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.02193\n",
      "Epoch 20/20\n",
      "129/129 [==============================] - 53s 403ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0281 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.02193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b36922be48>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_model_t62.fit(merged_cropped_augmented_train_set, validation_data = merged_valset, callbacks = [checkpoint], epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b24c07a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_testset = cropped_testset.concatenate(add_cropped_testset).shuffle(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0faf959",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'func_model_t6' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-be5365458de8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfunc_model_t6\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_testset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'func_model_t6' is not defined"
     ]
    }
   ],
   "source": [
    "func_model_t6.evaluate(merged_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2c73696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 7s 139ms/step - loss: 0.0390 - accuracy: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03900706022977829, 0.9893048405647278]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_model_t62.evaluate(merged_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe1431d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_saved_model_t62 = tf.keras.models.load_model('./kill_log_models/model_t62.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9ed1216",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 3s 110ms/step - loss: 0.0570 - accuracy: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05701206997036934, 0.9839572310447693]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_saved_model_t62.evaluate(merged_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5931c441",
   "metadata": {},
   "source": [
    "### 6차 파인튜닝 결과\n",
    "\n",
    "- 1차, 2차 평가 데이터의 정확도는 98.9%\n",
    "\n",
    "기존 파인튜닝하기 전의 6차 모델의 1,2차 평가 데이터의 정확도가 97.3%였습니다. 파인튜닝을 통해 약 1.6%의 정확도 상승을 확인할 수 있습니다.  \n",
    "\n",
    "파인튜닝을 통해서 기존 모델에 대한 고도화까지 진행해보았습니다. 이번에는 전이학습에 사용한 모델을 파라미터 수가 더 많은 VGG16로 변경하여 ResNet의 결과와 비교해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f39a2f9",
   "metadata": {},
   "source": [
    "## 7-1. 7차 학습\n",
    "\n",
    "\n",
    "### VGG16\n",
    "\n",
    "- 기존 모델 학습\n",
    "- ResNet50보다 복잡한 VGG16 사용\n",
    "\n",
    "\n",
    "### 1차 데이터셋\n",
    "\n",
    "- kill 이미지 786\n",
    "- non-kill 이미지 1832\n",
    "\n",
    "\n",
    "### 1차 테스트셋\n",
    "\n",
    "- kill 이미지 161\n",
    "- non-kill 이미지 149\n",
    "\n",
    "\n",
    "### 2차 데이터셋\n",
    "\n",
    "- kill 이미지 1009\n",
    "- non-kill 이미지 746\n",
    "\n",
    "\n",
    "### 2차 테스트셋\n",
    "\n",
    "- kill 이미지 252\n",
    "- non-kill 이미지 186\n",
    "\n",
    "\n",
    "### 7차 학습 특징\n",
    "\n",
    "\n",
    "- 전이학습을 통해 기존 모델을 1,2차 데이터셋을 결합하여 전체 데이터에 대한 학습을 진행합니다.\n",
    "- ROI을 추출한 뒤 Data Augmentation을 통해 데이터셋의 크기를 늘립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68bf123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.layers import Dense, ReLU, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4466bd6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(\n",
    "    include_top = False,\n",
    "    pooling = 'avg'\n",
    ")\n",
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59f08b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(190, 560, 3))\n",
    "# 해당 모델은 학습에 사용하지 않겠다를 명시한다. \n",
    "x = base_model(inputs, training=False)\n",
    "x =  Dense(32)(x)\n",
    "x =  BatchNormalization()(x)\n",
    "x =  ReLU()(x)\n",
    "outputs = Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "func_model_t7 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# 학습 루프 정의 \n",
    "func_model_t7.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86773ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model에 대한 체크포인트 생성 -> 가장 좋은 모델을 저장.\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"./kill_log_models/model_t7.hdf5\", monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bab84fad",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "129/129 [==============================] - 46s 301ms/step - loss: 0.3783 - accuracy: 0.8280 - val_loss: 0.0951 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09508, saving model to ./kill_log_models\\model_t7.hdf5\n",
      "Epoch 2/20\n",
      "129/129 [==============================] - 20s 147ms/step - loss: 0.1337 - accuracy: 0.9718 - val_loss: 0.0565 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09508 to 0.05647, saving model to ./kill_log_models\\model_t7.hdf5\n",
      "Epoch 3/20\n",
      "129/129 [==============================] - 20s 148ms/step - loss: 0.1089 - accuracy: 0.9759 - val_loss: 0.0518 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05647 to 0.05179, saving model to ./kill_log_models\\model_t7.hdf5\n",
      "Epoch 4/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0924 - accuracy: 0.9778 - val_loss: 0.0564 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05179\n",
      "Epoch 5/20\n",
      "129/129 [==============================] - 20s 148ms/step - loss: 0.0822 - accuracy: 0.9801 - val_loss: 0.0848 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05179\n",
      "Epoch 6/20\n",
      "129/129 [==============================] - 20s 148ms/step - loss: 0.0722 - accuracy: 0.9842 - val_loss: 0.0560 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05179\n",
      "Epoch 7/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0670 - accuracy: 0.9838 - val_loss: 0.0603 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05179\n",
      "Epoch 8/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0661 - accuracy: 0.9829 - val_loss: 0.0467 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.05179 to 0.04666, saving model to ./kill_log_models\\model_t7.hdf5\n",
      "Epoch 9/20\n",
      "129/129 [==============================] - 20s 150ms/step - loss: 0.0580 - accuracy: 0.9867 - val_loss: 0.0440 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04666 to 0.04400, saving model to ./kill_log_models\\model_t7.hdf5\n",
      "Epoch 10/20\n",
      "129/129 [==============================] - 20s 150ms/step - loss: 0.0521 - accuracy: 0.9873 - val_loss: 0.0704 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04400\n",
      "Epoch 11/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0510 - accuracy: 0.9863 - val_loss: 0.0530 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.04400\n",
      "Epoch 12/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0459 - accuracy: 0.9905 - val_loss: 0.0746 - val_accuracy: 0.9908\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.04400\n",
      "Epoch 13/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0411 - accuracy: 0.9905 - val_loss: 0.0714 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.04400\n",
      "Epoch 14/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0416 - accuracy: 0.9894 - val_loss: 0.0878 - val_accuracy: 0.9817\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.04400\n",
      "Epoch 15/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0359 - accuracy: 0.9902 - val_loss: 0.0453 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.04400\n",
      "Epoch 16/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0348 - accuracy: 0.9920 - val_loss: 0.0477 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.04400\n",
      "Epoch 17/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0333 - accuracy: 0.9910 - val_loss: 0.0528 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.04400\n",
      "Epoch 18/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0356 - accuracy: 0.9898 - val_loss: 0.0693 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.04400\n",
      "Epoch 19/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0306 - accuracy: 0.9921 - val_loss: 0.0387 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.04400 to 0.03871, saving model to ./kill_log_models\\model_t7.hdf5\n",
      "Epoch 20/20\n",
      "129/129 [==============================] - 20s 150ms/step - loss: 0.0257 - accuracy: 0.9938 - val_loss: 0.0770 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.03871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b5414e25c8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_model_t7.fit(merged_cropped_augmented_train_set, validation_data = merged_valset, callbacks = [checkpoint], epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5f8dcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 8s 317ms/step - loss: 0.0936 - accuracy: 0.9693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09361500293016434, 0.9692513346672058]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_model_t7.evaluate(merged_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9bdcea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_saved_model_t7 = tf.keras.models.load_model('./kill_log_models/model_t7.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a815e3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 3s 130ms/step - loss: 0.0628 - accuracy: 0.9853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06276007741689682, 0.9852941036224365]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_saved_model_t7.evaluate(merged_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbad7c8d",
   "metadata": {},
   "source": [
    "### 7차 학습의 결과\n",
    "\n",
    "- 학습 데이터의 가장 높은 정확도는 99%\n",
    "\n",
    "- 1,2차 평가 데이터의 정확도는 98.5%\n",
    " \n",
    "\n",
    "전이학습을 위해 사용하였던 기학습 모델을 ResNet 모델에서 VGG 모델로 변경하였습니다. VGG 모델은 ResNet 모델보다 layer의 수는 적으나 파라미터 수가 더 많다는 차이가 존재합니다. 이전 학습에서도 파인튜닝으로 모델을 고도화하여 정확도 향상을 확인하였기 때문에 VGG 모델에 대해서도 파인튜닝을 진행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3118cc",
   "metadata": {},
   "source": [
    "## 7-2. 7차 학습에 대한 파인튜닝\n",
    "\n",
    "평가 데이터의 정확도가 충분히 높기 때문에 파인튜닝을 통해서 현재 모델을 고도화하는 방법을 선택할 수 있습니다.\n",
    "\n",
    "\n",
    "### VGG16\n",
    "\n",
    "- 7차 학습 모델 사용\n",
    "\n",
    "\n",
    "### 1차 데이터셋 \n",
    "\n",
    "- kill 이미지 786\n",
    "- non-kill 이미지 1832\n",
    "\n",
    "\n",
    "### 1차 테스트셋\n",
    "\n",
    "- kill 이미지 161\n",
    "- non-kill 이미지 149\n",
    "\n",
    "\n",
    "### 2차 데이터셋\n",
    "\n",
    "- kill 이미지 1009\n",
    "- non-kill 이미지 746\n",
    "\n",
    "\n",
    "### 2차 테스트셋\n",
    "\n",
    "- kill 이미지 252\n",
    "- non-kill 이미지 186\n",
    "\n",
    "\n",
    "### 7차 파인튜닝 특징\n",
    "\n",
    "\n",
    "- 전이학습을 위해 가중치 갱신이 불가능하도록 설정한 것을 파인튜닝을 위해 가능하도록 설정합니다.\n",
    "- 1, 2차의 데이터셋을 결합합니다.\n",
    "- ROI을 추출한 뒤 Data Augmentation을 통해 데이터셋의 크기를 늘립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77d4bbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_model_t72 = tf.keras.models.load_model('./kill_log_models/model_t7.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1805443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_model_t72.layers[1].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20aca51e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 190, 560, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 14,731,265\n",
      "Trainable params: 14,731,201\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "func_model_t72.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08d7cc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loss에 따른 빠른 종료 -> 빠른 구현을 위해서 선택적으로 적용할 수 있다.\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# model에 대한 체크포인트 생성 -> 가장 좋은 모델을 저장. (모델을 저장하는 것은 ) \n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"./kill_log_models/model_t72.hdf5\", monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b85282ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_model_t72.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),  # Low learning rate\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "719ec86c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "129/129 [==============================] - 141s 735ms/step - loss: 0.0410 - accuracy: 0.9880 - val_loss: 0.0313 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03133, saving model to ./kill_log_models\\model_t72.hdf5\n",
      "Epoch 2/20\n",
      "129/129 [==============================] - 65s 503ms/step - loss: 0.0303 - accuracy: 0.9907 - val_loss: 0.0298 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03133 to 0.02981, saving model to ./kill_log_models\\model_t72.hdf5\n",
      "Epoch 3/20\n",
      "129/129 [==============================] - 66s 504ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.0276 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02981 to 0.02761, saving model to ./kill_log_models\\model_t72.hdf5\n",
      "Epoch 4/20\n",
      "129/129 [==============================] - 66s 505ms/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.0304 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02761\n",
      "Epoch 5/20\n",
      "129/129 [==============================] - 66s 505ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0316 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.02761\n",
      "Epoch 6/20\n",
      "129/129 [==============================] - 66s 505ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.0273 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02761 to 0.02726, saving model to ./kill_log_models\\model_t72.hdf5\n",
      "Epoch 7/20\n",
      "129/129 [==============================] - 66s 505ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0309 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.02726\n",
      "Epoch 8/20\n",
      "129/129 [==============================] - 66s 506ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.0284 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02726\n",
      "Epoch 9/20\n",
      "129/129 [==============================] - 66s 506ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0485 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02726\n",
      "Epoch 10/20\n",
      "129/129 [==============================] - 66s 505ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.0271 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02726 to 0.02710, saving model to ./kill_log_models\\model_t72.hdf5\n",
      "Epoch 11/20\n",
      "129/129 [==============================] - 66s 505ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0257 - val_accuracy: 0.9908\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02710 to 0.02569, saving model to ./kill_log_models\\model_t72.hdf5\n",
      "Epoch 12/20\n",
      "129/129 [==============================] - 66s 505ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 0.0283 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.02569\n",
      "Epoch 13/20\n",
      "129/129 [==============================] - 66s 506ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 0.0287 - val_accuracy: 0.9908\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.02569\n",
      "Epoch 14/20\n",
      "129/129 [==============================] - 66s 506ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.02569\n",
      "Epoch 15/20\n",
      "129/129 [==============================] - 66s 505ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.02569\n",
      "Epoch 16/20\n",
      "129/129 [==============================] - 669s 5s/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0317 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.02569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2274914e408>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_model_t72.fit(merged_cropped_augmented_train_set, validation_data = merged_valset, callbacks = [checkpoint, early_stop], epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7efb54f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 93s 4s/step - loss: 0.0407 - accuracy: 0.9920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0407470278441906, 0.9919785857200623]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_model_t72.evaluate(merged_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80af065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_saved_model_t72 = tf.keras.models.load_model('./kill_log_models/model_t72.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4519375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 38s 2s/step - loss: 0.0450 - accuracy: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.045024774968624115, 0.990641713142395]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_saved_model_t72.evaluate(merged_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0e26e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_model_t72.save('./kill_log_models/best_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244dd156",
   "metadata": {},
   "source": [
    "### 7차 파인튜닝의 결과\n",
    "\n",
    "- 학습 데이터의 가장 높은 정확도는 99%\n",
    "\n",
    "- 1,2차 평가 데이터의 정확도는 100%\n",
    " \n",
    "VGG 모델을 사용하여 구현한 모델의 정확도가 ResNet 모델을 사용하여 구현한 모델이 성능이 더 좋은 것을 확인할 수 있었습니다. 하지만 평가 데이터셋이 1,2차를 합치더라도 매우 적기 때문에 현재 모델의 성능을 판단하기 어렵습니다. 그러므로 새로 수집되는 리그오브레전드 이미지에 대해 모델을 적용해봄으로써 현재 모델의 성능을 판단해보겠습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
