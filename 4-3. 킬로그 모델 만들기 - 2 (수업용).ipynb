{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9781541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790f83db",
   "metadata": {},
   "source": [
    "## 5-1. 5차 학습 전 평가\n",
    "\n",
    "\n",
    "### 4차 학습 모델 \n",
    "\n",
    "- 기존 학습 방법들중 가장 성능이 좋은 모델 사용\n",
    "- VGG16보다 단순한 ResNet50을 전이학습을 진행하여 구현한 모델\n",
    "\n",
    "\n",
    "### 2차 데이터셋\n",
    "\n",
    "- kill 이미지 1261\n",
    "- non-kill 이미지 932\n",
    "\n",
    "현재 데이터가 학습과 평가 데이터가 구분되어있지 않습니다.\n",
    "\n",
    "### 5차 학습 전 평가 특징\n",
    "\n",
    "- 2차 데이터셋에서 ROI를 추출하여 평가 데이터로 사용합니다. \n",
    "- 2차 데이터셋 모두 사용하여 현재의 모델을 평가합니다. 추가된 데이터셋에 대한 정확도가 충분히 높다면 2차 데이터셋에 대한 학습이 필요하지 않기 때문입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "885bd5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADD_IMAGE_PATH = './dataset/kill_log_set_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f25f159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2193 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "add_train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    ADD_IMAGE_PATH,\n",
    "    label_mode = 'binary',\n",
    "    image_size = (540, 960),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79e121ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대충 본다.\n",
    "def crop_roi(image, label): \n",
    "    \n",
    "    cropped_image = tf.image.crop_to_bounding_box(\n",
    "        image, 10, 200, 190, 560\n",
    "    )\n",
    "    #resized_image = tf.image.resize(cropped_image, [190, 560], method = 'lanczos3')\n",
    "    #casted_image = resized_image / 255\n",
    "    return cropped_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5014404",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# ROI의 과정은 Data Augmentation의 수행이 아니므로 학습 데이터, 검증 데이터 모두 적용해야합니다.\n",
    "def make_crop_dataset(dataset):\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.map(crop_roi, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be4e5b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_cropped_dataset = make_crop_dataset(add_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "98e23e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_saved_model_t4 = tf.keras.models.load_model('./kill_log_models/model_t4.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b2a93676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 22s 311ms/step - loss: 0.1219 - accuracy: 0.9676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1219450831413269, 0.9676242470741272]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_saved_model_t4.evaluate(add_cropped_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5e7269",
   "metadata": {},
   "source": [
    "### 5차 학습전 평가의 결과\n",
    "\n",
    "\n",
    "- 평가 데이터의 정확도는 96.7%\n",
    "\n",
    "ROI를 추출하고, 추출된 이미지를 4차 학습 모델에 대해 평가한 결과, 기존의 98.7%에서 약 2%가 감소한 것을 확인할 수 있습니다. 2%의 감소는 2차 데이터셋에 대한 학습이 충분히 유의미할 수 있을 것으로 판단됩니다.\n",
    "\n",
    "- 랜덤하게 추출하여 2차 데이터셋을 2차 데이터셋(학습용), 2차 테스트셋으로 분류합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4577c3",
   "metadata": {},
   "source": [
    "## 5-2. 5차 학습 \n",
    "\n",
    "\n",
    "### ResNet\n",
    "\n",
    "- 4차 학습 모델 사용\n",
    "- VGG16보다 단순한 ResNet50사용\n",
    "\n",
    "\n",
    "### 1차 데이터셋 (기존 학습)\n",
    "\n",
    "- kill 이미지 786\n",
    "- non-kill 이미지 1832\n",
    "\n",
    "\n",
    "### 1차 테스트셋\n",
    "\n",
    "- kill 이미지 161\n",
    "- non-kill 이미지 149\n",
    "\n",
    "\n",
    "### 2차 데이터셋\n",
    "\n",
    "- kill 이미지 1009\n",
    "- non-kill 이미지 746\n",
    "\n",
    "\n",
    "### 2차 테스트셋\n",
    "\n",
    "- kill 이미지 252\n",
    "- non-kill 이미지 186\n",
    "\n",
    "\n",
    "### 5차 학습 특징\n",
    "\n",
    "- ROI를 수행합니다.\n",
    "- 2차 테스트 셋으로 4차 학습 모델을 평가합니다.\n",
    "- 그 후, 4차 학습 모델을 2차 데이터 셋으로 추가학습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8f888b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADD_TRAIN_PATH = './cropped_dataset/kill_log_dataset_2'\n",
    "ADD_TEST_PATH = './cropped_dataset/kill_log_testset_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9e211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dca70896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model에 대한 체크포인트 생성 -> 가장 좋은 모델을 저장. (모델을 저장하는 것은 ) \n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"./kill_log_models/model_t5.hdf5\", monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42a44812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d0767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 추가학습 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bbf638a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 125ms/step - loss: 0.0880 - accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08803118765354156, 0.9771689772605896]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a61a8940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 좋은 모델 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f7183bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 111ms/step - loss: 0.0880 - accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08803118765354156, 0.9771689772605896]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 좋은 모델 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaafa35b",
   "metadata": {},
   "source": [
    "## 5-3. 1차 테스트 셋에 대한 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e5d593f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 310 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 1차 테스트셋 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fb362187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 110ms/step - loss: 0.0106 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01064381469041109, 1.0]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1차 테스트셋 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ac6717",
   "metadata": {},
   "source": [
    "### 5차 학습 결과\n",
    "\n",
    "- 1차 평가 데이터의 정확도는 100%\n",
    "- 2차 평가 데이터의 정확도는 97.7%\n",
    "\n",
    "2차 평가 데이터에 대해서도 추가 학습 모델의 정확도가 매우 높은 것을 확인할 수 있습니다. 이전 학습에서 Data Augmentation을 통한 정확도 개선을 확인하였으므로 현재의 학습 방법에 Data Augmentation까지 추가하여 학습을 진행해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a1a151",
   "metadata": {},
   "source": [
    "## 6-1. 6차 학습\n",
    "\n",
    "\n",
    "### ResNet\n",
    "\n",
    "- 4차 학습 모델 사용\n",
    "- VGG16보다 단순한 ResNet50사용\n",
    "\n",
    "\n",
    "### 1차 데이터셋 (기존 학습)\n",
    "\n",
    "- kill 이미지 786\n",
    "- non-kill 이미지 1832\n",
    "\n",
    "\n",
    "### 1차 테스트셋\n",
    "\n",
    "- kill 이미지 161\n",
    "- non-kill 이미지 149\n",
    "\n",
    "\n",
    "### 2차 데이터셋\n",
    "\n",
    "- kill 이미지 1009\n",
    "- non-kill 이미지 746\n",
    "\n",
    "\n",
    "### 2차 테스트셋\n",
    "\n",
    "- kill 이미지 252\n",
    "- non-kill 이미지 186\n",
    "\n",
    "\n",
    "### 6차 학습 특징\n",
    "\n",
    "\n",
    "- 4차 학습 모델을 2차 데이터 셋으로 추가학습을 진행합니다.\n",
    "- ROI을 추출한 뒤 Data Augmentation을 통해 데이터셋의 크기를 늘립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d8b3cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation 구현 들고오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa43e4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceff2961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d19972d2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_augmented_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-9aaf44e0f3f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Data Augmentation 적용\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#add_cropped_trainset = make_crop_dataset(add_train_dataset)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0madd_cropped_augmented_train_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_augmented_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_cropped_trainset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# validation, test set은 그대로 사용\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'make_augmented_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Data Augmentation 적용\n",
    "\n",
    "# validation, test set은 그대로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "664143f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model에 대한 체크포인트 생성 -> 가장 좋은 모델을 저장. (모델을 저장하는 것은 ) \n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"./kill_log_models/model_t6.hdf5\", monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbd27722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f85e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 추가학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bd5b0843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 110ms/step - loss: 0.0958 - accuracy: 0.9703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09581686556339264, 0.9703196287155151]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c732ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 좋은 모델 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cd97a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 좋은 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "be662d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 108ms/step - loss: 0.0106 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01064381469041109, 1.0]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 좋은 모델 1차 데이터로 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b8d7d3",
   "metadata": {},
   "source": [
    "### 6차 학습의 결과\n",
    "\n",
    "- 학습 데이터의 가장 높은 정확도는 99%\n",
    "\n",
    "- 1차 평가 데이터의 정확도는 100%\n",
    "\n",
    "- 2차 평가 데이터의 정확도는 97.7%\n",
    "\n",
    "ROI 추출 및 Data Augmentation까지 추가하여 학습을 진행해보았으나, 5차 학습과의 정확도 차이가 발생하지 않았습니다. 이로 미루어볼 때, 2차 학습 데이터를 추가학습한 5차 모델은 Data Augmentation를 통해 생성되는 새로운 이미지들에 대해서도 충분히 예측가능하다는 것으로 생각해볼 수 있습니다. 여러가지 학습 방법으로 학습을 진행해보았습니다. 가장 좋은 모델인 6차 학습 모델에 대해서 파인튜닝을 통해 정확도를 향상시키도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05091893",
   "metadata": {},
   "source": [
    "## 6-2. 6차 학습에 대한 파인튜닝\n",
    "\n",
    "평가 데이터의 정확도가 충분히 높기 때문에 파인튜닝을 통해서 현재 모델을 고도화하는 방법을 선택할 수 있습니다.\n",
    "\n",
    "\n",
    "### ResNet\n",
    "\n",
    "- 6차 학습 모델 사용\n",
    "- VGG16보다 단순한 ResNet50사용\n",
    "\n",
    "\n",
    "### 1차 데이터셋 \n",
    "\n",
    "- kill 이미지 786\n",
    "- non-kill 이미지 1832\n",
    "\n",
    "\n",
    "### 1차 테스트셋\n",
    "\n",
    "- kill 이미지 161\n",
    "- non-kill 이미지 149\n",
    "\n",
    "\n",
    "### 2차 데이터셋\n",
    "\n",
    "- kill 이미지 1009\n",
    "- non-kill 이미지 746\n",
    "\n",
    "\n",
    "### 2차 테스트셋\n",
    "\n",
    "- kill 이미지 252\n",
    "- non-kill 이미지 186\n",
    "\n",
    "\n",
    "### 6차 파인튜닝 특징\n",
    "\n",
    "\n",
    "- 전이학습을 위해 가중치 갱신이 불가능하도록 설정한 것을 파인튜닝을 위해 가능하도록 설정합니다.\n",
    "- 1, 2차의 데이터셋을 결합합니다.\n",
    "- ROI을 추출한 뒤 Data Augmentation을 통해 데이터셋의 크기를 늘립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9a90e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6차 모델 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16bbd4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6차 모델 학습 가능하도록 변경하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e6685e",
   "metadata": {},
   "source": [
    "### 데이터셋 구성하기\n",
    "\n",
    "- 1차 데이터셋 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5360ce9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2618 files belonging to 2 classes.\n",
      "Using 2357 files for training.\n",
      "Found 2618 files belonging to 2 classes.\n",
      "Using 261 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# 1차 데이터셋 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c62ce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1, 2차 데이터셋이 결합된 데이터셋\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "236a3ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1, 2차 데이터셋이 결합된 데이터셋\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bf69cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결합된 데이터셋에 Data Augmentation 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03960d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loss에 따른 빠른 종료 -> 빠른 구현을 위해서 선택적으로 적용할 수 있다.\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# model에 대한 체크포인트 생성 -> 가장 좋은 모델을 저장. (모델을 저장하는 것은 ) \n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"./kill_log_models/model_t62.hdf5\", monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79bd2831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝을 위한 학습루프 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee8f19ec",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "129/129 [==============================] - 102s 478ms/step - loss: 0.0883 - accuracy: 0.9738 - val_loss: 0.0502 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05015, saving model to ./kill_log_models\\model_t62.hdf5\n",
      "Epoch 2/20\n",
      "129/129 [==============================] - 52s 401ms/step - loss: 0.0460 - accuracy: 0.9831 - val_loss: 0.0401 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05015 to 0.04014, saving model to ./kill_log_models\\model_t62.hdf5\n",
      "Epoch 3/20\n",
      "129/129 [==============================] - 53s 402ms/step - loss: 0.0270 - accuracy: 0.9931 - val_loss: 0.0601 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04014\n",
      "Epoch 4/20\n",
      "129/129 [==============================] - 53s 402ms/step - loss: 0.0294 - accuracy: 0.9914 - val_loss: 0.0342 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04014 to 0.03422, saving model to ./kill_log_models\\model_t62.hdf5\n",
      "Epoch 5/20\n",
      "129/129 [==============================] - 53s 402ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.0326 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.03422 to 0.03264, saving model to ./kill_log_models\\model_t62.hdf5\n",
      "Epoch 6/20\n",
      "129/129 [==============================] - 53s 403ms/step - loss: 0.0118 - accuracy: 0.9978 - val_loss: 0.0321 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.03264 to 0.03209, saving model to ./kill_log_models\\model_t62.hdf5\n",
      "Epoch 7/20\n",
      "129/129 [==============================] - 55s 422ms/step - loss: 0.0110 - accuracy: 0.9981 - val_loss: 0.0266 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.03209 to 0.02657, saving model to ./kill_log_models\\model_t62.hdf5\n",
      "Epoch 8/20\n",
      "129/129 [==============================] - 53s 403ms/step - loss: 0.0095 - accuracy: 0.9989 - val_loss: 0.0272 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02657\n",
      "Epoch 9/20\n",
      "129/129 [==============================] - 53s 404ms/step - loss: 0.0095 - accuracy: 0.9993 - val_loss: 0.0336 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02657\n",
      "Epoch 10/20\n",
      "129/129 [==============================] - 53s 404ms/step - loss: 0.0077 - accuracy: 0.9994 - val_loss: 0.0281 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02657\n",
      "Epoch 11/20\n",
      "129/129 [==============================] - 53s 403ms/step - loss: 0.0063 - accuracy: 0.9999 - val_loss: 0.0249 - val_accuracy: 0.9977\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02657 to 0.02485, saving model to ./kill_log_models\\model_t62.hdf5\n",
      "Epoch 12/20\n",
      "129/129 [==============================] - 53s 403ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.0343 - val_accuracy: 0.9908\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.02485\n",
      "Epoch 13/20\n",
      "129/129 [==============================] - 53s 403ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.02485\n",
      "Epoch 14/20\n",
      "129/129 [==============================] - 53s 403ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0365 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.02485\n",
      "Epoch 15/20\n",
      "129/129 [==============================] - 53s 404ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.0280 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.02485\n",
      "Epoch 16/20\n",
      "129/129 [==============================] - 53s 403ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.0321 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.02485\n",
      "Epoch 17/20\n",
      "129/129 [==============================] - 53s 404ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.0219 - val_accuracy: 0.9977\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.02485 to 0.02193, saving model to ./kill_log_models\\model_t62.hdf5\n",
      "Epoch 18/20\n",
      "129/129 [==============================] - 53s 403ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.0312 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.02193\n",
      "Epoch 19/20\n",
      "129/129 [==============================] - 53s 403ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 0.9977\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.02193\n",
      "Epoch 20/20\n",
      "129/129 [==============================] - 53s 403ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0281 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.02193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b36922be48>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파인튜닝을 위한 전체 데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b24c07a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 데이터 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0faf959",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'func_model_t6' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-be5365458de8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfunc_model_t6\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_testset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'func_model_t6' is not defined"
     ]
    }
   ],
   "source": [
    "# 파인튜닝전 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44614e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝후 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe1431d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 좋은 모델 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9ed1216",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 3s 110ms/step - loss: 0.0570 - accuracy: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05701206997036934, 0.9839572310447693]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 좋은 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5931c441",
   "metadata": {},
   "source": [
    "### 6차 파인튜닝 결과\n",
    "\n",
    "- 1차, 2차 평가 데이터의 정확도는 98.9%\n",
    "\n",
    "기존 파인튜닝하기 전의 6차 모델의 1,2차 평가 데이터의 정확도가 97.3%였습니다. 파인튜닝을 통해 약 1.6%의 정확도 상승을 확인할 수 있습니다.  \n",
    "\n",
    "파인튜닝을 통해서 기존 모델에 대한 고도화까지 진행해보았습니다. 이번에는 전이학습에 사용한 모델을 파라미터 수가 더 많은 VGG16로 변경하여 ResNet의 결과와 비교해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f39a2f9",
   "metadata": {},
   "source": [
    "## 7-1. 7차 학습\n",
    "\n",
    "\n",
    "### VGG16\n",
    "\n",
    "- 기존 모델 학습\n",
    "- ResNet50보다 복잡한 VGG16 사용\n",
    "\n",
    "\n",
    "### 1차 데이터셋\n",
    "\n",
    "- kill 이미지 786\n",
    "- non-kill 이미지 1832\n",
    "\n",
    "\n",
    "### 1차 테스트셋\n",
    "\n",
    "- kill 이미지 161\n",
    "- non-kill 이미지 149\n",
    "\n",
    "\n",
    "### 2차 데이터셋\n",
    "\n",
    "- kill 이미지 1009\n",
    "- non-kill 이미지 746\n",
    "\n",
    "\n",
    "### 2차 테스트셋\n",
    "\n",
    "- kill 이미지 252\n",
    "- non-kill 이미지 186\n",
    "\n",
    "\n",
    "### 7차 학습 특징\n",
    "\n",
    "\n",
    "- 전이학습을 통해 기존 모델을 1,2차 데이터셋을 결합하여 전체 데이터에 대한 학습을 진행합니다.\n",
    "- ROI을 추출한 뒤 Data Augmentation을 통해 데이터셋의 크기를 늘립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68bf123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.layers import Dense, ReLU, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4466bd6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VGG 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59f08b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86773ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model에 대한 체크포인트 생성 -> 가장 좋은 모델을 저장.\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"./kill_log_models/model_t7.hdf5\", monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bab84fad",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "129/129 [==============================] - 46s 301ms/step - loss: 0.3783 - accuracy: 0.8280 - val_loss: 0.0951 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09508, saving model to ./kill_log_models\\model_t7.hdf5\n",
      "Epoch 2/20\n",
      "129/129 [==============================] - 20s 147ms/step - loss: 0.1337 - accuracy: 0.9718 - val_loss: 0.0565 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09508 to 0.05647, saving model to ./kill_log_models\\model_t7.hdf5\n",
      "Epoch 3/20\n",
      "129/129 [==============================] - 20s 148ms/step - loss: 0.1089 - accuracy: 0.9759 - val_loss: 0.0518 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05647 to 0.05179, saving model to ./kill_log_models\\model_t7.hdf5\n",
      "Epoch 4/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0924 - accuracy: 0.9778 - val_loss: 0.0564 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05179\n",
      "Epoch 5/20\n",
      "129/129 [==============================] - 20s 148ms/step - loss: 0.0822 - accuracy: 0.9801 - val_loss: 0.0848 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05179\n",
      "Epoch 6/20\n",
      "129/129 [==============================] - 20s 148ms/step - loss: 0.0722 - accuracy: 0.9842 - val_loss: 0.0560 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05179\n",
      "Epoch 7/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0670 - accuracy: 0.9838 - val_loss: 0.0603 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05179\n",
      "Epoch 8/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0661 - accuracy: 0.9829 - val_loss: 0.0467 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.05179 to 0.04666, saving model to ./kill_log_models\\model_t7.hdf5\n",
      "Epoch 9/20\n",
      "129/129 [==============================] - 20s 150ms/step - loss: 0.0580 - accuracy: 0.9867 - val_loss: 0.0440 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04666 to 0.04400, saving model to ./kill_log_models\\model_t7.hdf5\n",
      "Epoch 10/20\n",
      "129/129 [==============================] - 20s 150ms/step - loss: 0.0521 - accuracy: 0.9873 - val_loss: 0.0704 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04400\n",
      "Epoch 11/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0510 - accuracy: 0.9863 - val_loss: 0.0530 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.04400\n",
      "Epoch 12/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0459 - accuracy: 0.9905 - val_loss: 0.0746 - val_accuracy: 0.9908\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.04400\n",
      "Epoch 13/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0411 - accuracy: 0.9905 - val_loss: 0.0714 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.04400\n",
      "Epoch 14/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0416 - accuracy: 0.9894 - val_loss: 0.0878 - val_accuracy: 0.9817\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.04400\n",
      "Epoch 15/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0359 - accuracy: 0.9902 - val_loss: 0.0453 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.04400\n",
      "Epoch 16/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0348 - accuracy: 0.9920 - val_loss: 0.0477 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.04400\n",
      "Epoch 17/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0333 - accuracy: 0.9910 - val_loss: 0.0528 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.04400\n",
      "Epoch 18/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0356 - accuracy: 0.9898 - val_loss: 0.0693 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.04400\n",
      "Epoch 19/20\n",
      "129/129 [==============================] - 20s 149ms/step - loss: 0.0306 - accuracy: 0.9921 - val_loss: 0.0387 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.04400 to 0.03871, saving model to ./kill_log_models\\model_t7.hdf5\n",
      "Epoch 20/20\n",
      "129/129 [==============================] - 20s 150ms/step - loss: 0.0257 - accuracy: 0.9938 - val_loss: 0.0770 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.03871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b5414e25c8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5f8dcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 8s 317ms/step - loss: 0.0936 - accuracy: 0.9693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09361500293016434, 0.9692513346672058]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9bdcea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 좋은 모델 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a815e3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 3s 130ms/step - loss: 0.0628 - accuracy: 0.9853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06276007741689682, 0.9852941036224365]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 좋은 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbad7c8d",
   "metadata": {},
   "source": [
    "### 7차 학습의 결과\n",
    "\n",
    "- 학습 데이터의 가장 높은 정확도는 99%\n",
    "\n",
    "- 1,2차 평가 데이터의 정확도는 98.5%\n",
    " \n",
    "\n",
    "전이학습을 위해 사용하였던 기학습 모델을 ResNet 모델에서 VGG 모델로 변경하였습니다. VGG 모델은 ResNet 모델보다 layer의 수는 적으나 파라미터 수가 더 많다는 차이가 존재합니다. 이전 학습에서도 파인튜닝으로 모델을 고도화하여 정확도 향상을 확인하였기 때문에 VGG 모델에 대해서도 파인튜닝을 진행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3118cc",
   "metadata": {},
   "source": [
    "## 7-2. 7차 학습에 대한 파인튜닝\n",
    "\n",
    "평가 데이터의 정확도가 충분히 높기 때문에 파인튜닝을 통해서 현재 모델을 고도화하는 방법을 선택할 수 있습니다.\n",
    "\n",
    "\n",
    "### VGG16\n",
    "\n",
    "- 7차 학습 모델 사용\n",
    "\n",
    "\n",
    "### 1차 데이터셋 \n",
    "\n",
    "- kill 이미지 786\n",
    "- non-kill 이미지 1832\n",
    "\n",
    "\n",
    "### 1차 테스트셋\n",
    "\n",
    "- kill 이미지 161\n",
    "- non-kill 이미지 149\n",
    "\n",
    "\n",
    "### 2차 데이터셋\n",
    "\n",
    "- kill 이미지 1009\n",
    "- non-kill 이미지 746\n",
    "\n",
    "\n",
    "### 2차 테스트셋\n",
    "\n",
    "- kill 이미지 252\n",
    "- non-kill 이미지 186\n",
    "\n",
    "\n",
    "### 7차 파인튜닝 특징\n",
    "\n",
    "\n",
    "- 전이학습을 위해 가중치 갱신이 불가능하도록 설정한 것을 파인튜닝을 위해 가능하도록 설정합니다.\n",
    "- 1, 2차의 데이터셋을 결합합니다.\n",
    "- ROI을 추출한 뒤 Data Augmentation을 통해 데이터셋의 크기를 늘립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77d4bbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7차 모델 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1805443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7차 모델 학습 가능하도록 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08d7cc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loss에 따른 빠른 종료 -> 빠른 구현을 위해서 선택적으로 적용할 수 있다.\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# model에 대한 체크포인트 생성 -> 가장 좋은 모델을 저장. (모델을 저장하는 것은 ) \n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"./kill_log_models/model_t72.hdf5\", monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b85282ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝을 위한 학습루프 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "719ec86c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "129/129 [==============================] - 141s 735ms/step - loss: 0.0410 - accuracy: 0.9880 - val_loss: 0.0313 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03133, saving model to ./kill_log_models\\model_t72.hdf5\n",
      "Epoch 2/20\n",
      "129/129 [==============================] - 65s 503ms/step - loss: 0.0303 - accuracy: 0.9907 - val_loss: 0.0298 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03133 to 0.02981, saving model to ./kill_log_models\\model_t72.hdf5\n",
      "Epoch 3/20\n",
      "129/129 [==============================] - 66s 504ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.0276 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02981 to 0.02761, saving model to ./kill_log_models\\model_t72.hdf5\n",
      "Epoch 4/20\n",
      "129/129 [==============================] - 66s 505ms/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.0304 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02761\n",
      "Epoch 5/20\n",
      "129/129 [==============================] - 66s 505ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0316 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.02761\n",
      "Epoch 6/20\n",
      "129/129 [==============================] - 66s 505ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.0273 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02761 to 0.02726, saving model to ./kill_log_models\\model_t72.hdf5\n",
      "Epoch 7/20\n",
      "129/129 [==============================] - 66s 505ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0309 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.02726\n",
      "Epoch 8/20\n",
      "129/129 [==============================] - 66s 506ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.0284 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02726\n",
      "Epoch 9/20\n",
      "129/129 [==============================] - 66s 506ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0485 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02726\n",
      "Epoch 10/20\n",
      "129/129 [==============================] - 66s 505ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.0271 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02726 to 0.02710, saving model to ./kill_log_models\\model_t72.hdf5\n",
      "Epoch 11/20\n",
      "129/129 [==============================] - 66s 505ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0257 - val_accuracy: 0.9908\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02710 to 0.02569, saving model to ./kill_log_models\\model_t72.hdf5\n",
      "Epoch 12/20\n",
      "129/129 [==============================] - 66s 505ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 0.0283 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.02569\n",
      "Epoch 13/20\n",
      "129/129 [==============================] - 66s 506ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 0.0287 - val_accuracy: 0.9908\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.02569\n",
      "Epoch 14/20\n",
      "129/129 [==============================] - 66s 506ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.02569\n",
      "Epoch 15/20\n",
      "129/129 [==============================] - 66s 505ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.02569\n",
      "Epoch 16/20\n",
      "129/129 [==============================] - 669s 5s/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0317 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.02569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2274914e408>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파인튜닝을 위한 추가 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7efb54f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 93s 4s/step - loss: 0.0407 - accuracy: 0.9920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0407470278441906, 0.9919785857200623]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파인튜닝 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80af065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 좋은 모델 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4519375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 38s 2s/step - loss: 0.0450 - accuracy: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.045024774968624115, 0.990641713142395]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 좋은 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0e26e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지금까지 best 모델 저장하기\n",
    "func_model_t72.save('./kill_log_models/best_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244dd156",
   "metadata": {},
   "source": [
    "### 7차 파인튜닝의 결과\n",
    "\n",
    "- 학습 데이터의 가장 높은 정확도는 99%\n",
    "\n",
    "- 1,2차 평가 데이터의 정확도는 100%\n",
    " \n",
    "VGG 모델을 사용하여 구현한 모델의 정확도가 ResNet 모델을 사용하여 구현한 모델이 성능이 더 좋은 것을 확인할 수 있었습니다. 하지만 평가 데이터셋이 1,2차를 합치더라도 매우 적기 때문에 현재 모델의 성능을 판단하기 어렵습니다. 그러므로 새로 수집되는 리그오브레전드 이미지에 대해 모델을 적용해봄으로써 현재 모델의 성능을 판단해보겠습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
