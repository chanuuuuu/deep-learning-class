{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fff4bc83",
   "metadata": {},
   "source": [
    "# TensorFlow란?\n",
    "\n",
    "구글에서 만든 딥러닝 플랫폼으로 가장 많이 사용되는 딥러닝 라이브러리이다. \n",
    "\n",
    "1. 프레임워크   \n",
    "    문제해결을 위한 기본 개념 구조. 개발할 수 있도록 필요한 기능들을 제공한다. \n",
    "    \n",
    "2. 라이브러리  \n",
    "    기능 구현에 있어서 필요한 비휘발성 자원의 모임.\n",
    "    \n",
    "    \n",
    "- 우리의 학습은 2.0을 기준으로 진행한다.\n",
    "- 러닝커브가 가파르다. 아래의 특징들이 텐서플로우를 어렵게 만든다.\n",
    "    1. *'tensor'*의 개념\n",
    "    2. 내부 실행 구조가 '*graph*'를 사용한  *'lazy evaluation'* 방식이다.\n",
    "    \n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a2decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379be893",
   "metadata": {},
   "source": [
    "# 1. Tensor(텐서)의 개념\n",
    "\n",
    "> 텐서플로우에서 사용되는 `데이터를 담는 그릇`으로,  모든 원소가 동일한 type을 가지는 다차원 배열이다.\n",
    "\n",
    "- numpy를 알고 있다면 numpy의 array와 동일하다. \n",
    "→ 실제로 numpy의 데이터 타입을 기본적으로 사용한다.\n",
    "\n",
    "\n",
    "- tensorflow의 모든 데이터는 tensor를 통해 정의된다.\n",
    "\n",
    "\n",
    "- 텐서가 선언되었다면 내부 데이터를 업데이트 할 수 없으며, 값이 갱신되는 대신, 갱신된 값으로 새로운 tensor가 생성되는 방식이다. 하지만 특정 텐서는 method를 사용하면 내부의 값을 갱신할 수 있다. (*tf.Variable*)\n",
    "\n",
    "\n",
    "두 가지 중요한 속성 타입, 차원은 반드시 텐서에 정의되어야만 한다.\n",
    "\n",
    "** 텐서를 선언할때 변수명을 구분되도록 선언하자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e1a622",
   "metadata": {},
   "source": [
    "# 1-1. 차원\n",
    "\n",
    "텐서는 `다차원`배열이라고 정의하였다.   \n",
    "차원의 갯수 즉, 데이터가 표현되는 축의 갯수를 rank라고 하는데, 모든 텐서는 rank값을 가진다.  \n",
    "이 rank 값으로 데이터의 종류가 구별되는데, `.ndim` method를 통해서 rank를 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8eb967",
   "metadata": {},
   "source": [
    "## 1. scalar\n",
    "\n",
    "rank = 0,  0차원의 데이터이다. 하나의 값을 가진다.\n",
    "\n",
    "#### constant(상수)\n",
    "\n",
    "텐서의 자료형으로, 프로그램 종료시까지 데이터가 변하지 않는 특성을 가지는 텐서이다.  \n",
    "\n",
    "`tf.constant` 클래스를 통해 생성하며, 반드시 초기값이 존재해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수\n",
    "\n",
    "\n",
    "# 실수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f2b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f22c3",
   "metadata": {},
   "source": [
    "## 2. vector\n",
    "\n",
    "rank = 1, 1차원의 데이터로 하나의 축을 가지는 배열으로 생각하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10c892d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be46396b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bec144eb",
   "metadata": {},
   "source": [
    "## 3. matrix\n",
    "\n",
    "rank = 2, 2차원의 데이터로  두개의 축을 가진 행렬의 형태를 가진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b7b203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7103806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2921ea27",
   "metadata": {},
   "source": [
    "## 이외의 다차원 텐서도 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb368b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tf.constant([\n",
    "  [[0, 1, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9]],\n",
    "  [[10, 11, 12, 13, 14],\n",
    "   [15, 16, 17, 18, 19]],\n",
    "  [[20, 21, 22, 23, 24],\n",
    "   [25, 26, 27, 28, 29]],])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcefc99f",
   "metadata": {},
   "source": [
    "각 텐서들의 출력을 살펴보면 모두 내부 값 뿐 아니라, shape 도 함께 출력된다.   \n",
    "shape는 텐서의 각 차원의 길이를 말한다.   \n",
    "예로 다차원의 텐서의 첫 번째 차원의 길이는 3, 두 번째 차원의 길이는 2, 세 번째 차원의 길이는 5이기 때문에 해당 텐서의 shape는 (3, 2, 5)가 된다. \n",
    "\n",
    "\n",
    "\n",
    "모든 텐서는 차원의 갯수, 각 차원의 길이인 shape가 반드시 정의되어야한다.   \n",
    "shape를 명시하여 정의하거나 초기값을 통해 자동으로 shape를 정의하는 과정이 명시되어야한다. \n",
    "이외에 shape와 같은 텐서에 대한 여러가지 개념을 아래에서 소개한다.  \n",
    "  \n",
    "\n",
    "- numpy를 알고 있다면 numpy의 array와 동일하다.   \n",
    "→ 실제로 numpy의 데이터 타입을 기본적으로 사용한다.  \n",
    "\n",
    "\n",
    "- tensorflow의 모든 데이터는 tensor를 통해 정의된다.\n",
    "\n",
    "\n",
    "- 텐서가 선언되었다면 내부 데이터를 업데이트 할 수 없으며, 값이 갱신되는 대신, 갱신된 값으로 새로운 tensor가 생성되는 방식이다. 하지만 특정 텐서는 method를 사용하면 내부의 값을 갱신할 수 있다. (*tf.Variable*)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008d54ea",
   "metadata": {},
   "source": [
    "# 1-2. 텐서에 대한 여러가지 개념\n",
    "\n",
    "\n",
    "1. rank\n",
    "2. shape\n",
    "3. axis, dim\n",
    "4. size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4d98b9",
   "metadata": {},
   "source": [
    "### rank\n",
    "\n",
    "텐서의 차원의 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19512695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d55823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac669f2b",
   "metadata": {},
   "source": [
    "## shape\n",
    "\n",
    "텐서의 각 차원의 길이 (element의 수)\n",
    "\n",
    "#### shape를 계산하는 방법\n",
    "\n",
    "1. []를 하나씩 제거하여 내부의 원소 갯수를 계수한다.\n",
    "2. 내부 원소 중 하나를 선택하여 1의 순서를 반복한다.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "# shape 계산 예제\n",
    "[ [[0, 1, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9]],\n",
    "  [[10, 11, 12, 13, 14],\n",
    "   [15, 16, 17, 18, 19]],\n",
    "  [[20, 21, 22, 23, 24],\n",
    "   [25, 26, 27, 28, 29]],])\n",
    "\n",
    "# 1번 수행 -> 가장 바깥의 []을 제거하여 원소의 갯수를 센다 -> 3\n",
    "  [[0, 1, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9]],\n",
    "  [[10, 11, 12, 13, 14],\n",
    "   [15, 16, 17, 18, 19]],\n",
    "  [[20, 21, 22, 23, 24],\n",
    "   [25, 26, 27, 28, 29]]\n",
    "\n",
    "# 2번 수행 -> 배열의 하나의 원소를 택하여 1번을 수행한다.\n",
    "  [[0, 1, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9]]\n",
    "\n",
    "# 다시 1번 수행 -> 가장 바깥의 []을 제거하여 원소의 갯수를 센다 -> 2\n",
    " [0, 1, 2, 3, 4],\n",
    " [5, 6, 7, 8, 9]\n",
    "\n",
    "# 다시 2번 수행 -> 배열의 하나의 원소를 택하여 1번을 수행한다.\n",
    " [0, 1, 2, 3, 4]\n",
    "\n",
    "# 다시 1번 수행 -> 가장 바깥의 []을 제거하여 원소의 갯수를 센다 -> 5\n",
    "\t0, 1, 2, 3, 4\n",
    "\n",
    "# 즉, shape는 (3, 2, 5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66b2fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc559c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5434bd94",
   "metadata": {},
   "source": [
    "## axis, dim\n",
    "\n",
    "텐서의 특정 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11635ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "993723bc",
   "metadata": {},
   "source": [
    "## size\n",
    "\n",
    "텐서의 총 원소 갯수\n",
    "\n",
    "모든 차원의 길이의 곱\n",
    "\n",
    "`tf.size()`를 통해 데이터 size를 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecbf2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ff85192",
   "metadata": {},
   "source": [
    "# 1-3. 원소의 타입\n",
    "\n",
    "텐서는 기본적으로 numpy.array을 사용한다.  \n",
    "텐서는 모든 원소가 동일한 타입을 가진다.(numpy.array와 동일한 개념이다.) 주요 특징은 아래와 같다.\n",
    "\n",
    "- 주로 숫자 데이터를 사용하기 때문에 float, int를 사용하는데 이 때 값의 표현범위를 정의하기 위해 사용되는 bit 수를 뒤에 추가한다.   \n",
    "    예로 float32, float64, int32, int64 가 사용된다.   \n",
    "    \n",
    "\n",
    "- 문자열 등 수가 아닌 다른 타입도 사용할 수 있지만 하나의 텐서에는 하나의 타입만 사용할 수 있다. (모든 원소 가 동일한 타입이어야 하므로)\n",
    "\n",
    "\n",
    "- 텐서의 데이터는 직사각형의 구조이어야 한다.   \n",
    "    > 텐서를 구성하는 축(axis, dim)마다 모든 요소의 크기가 같다는 것을 의미\n",
    "    > 모든 요소의 크기가 동일하지 않다면 shape를 정의할 수 없다.\n",
    "    > 희소행렬을 처리하는 SparseTensor처럼 직사각형이 아닌 것도 있지만 학습 범위 밖이다.\n",
    "    ```\n",
    "    # ex.1 (3, ?)\n",
    "    [\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8]\n",
    "    ]\n",
    "\n",
    "    # ex.2 \n",
    "    [ [[0, 1, 3, 4],\n",
    "       [5, 6, 7, 8, 9]],\n",
    "      [[10, 11, 12, 13, 14],\n",
    "       [15, 19]],\n",
    "      [[20, 21, 22, 23, 24],\n",
    "       [25, 26, 27, 28, 29, 30, 31]],])\n",
    "    ```\n",
    "\n",
    "__모든 텐서는 원소의 타입인 dtype이 반드시 정의되어야한다. dtype을 명시하거나 초기값을 통해 자동으로 dtype를 정의한다.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f044ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf543d76",
   "metadata": {},
   "source": [
    "# 1-4. 텐서의 자료형\n",
    "\n",
    "텐서를 `데이터를 담는 그릇`으로 정의하였다.   \n",
    "텐서의 자료형은 여러가지이지만 그 중에 두 개만 설명하고자 한다.   \n",
    "이 그릇들은 앞에서 설명했던 데이터의 차원과 원소의 타입이 명시되어야한다는 특성은 그대로 가진다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492f7efd",
   "metadata": {},
   "source": [
    "## constant(상수)\n",
    "\n",
    "프로그램 종료시까지 데이터가 변하지 않는 특성을 가지는 텐서이다. \n",
    "\n",
    "- tf.constant 클래스를 통해 생성하며, 반드시 초기값이 존재해야한다.  \n",
    "    → shape, dtype을 명시하지 않아도 가능하지만 명시하는 것이 좋다.\n",
    "     \n",
    "     \n",
    "- 상수와 동일하게 값이 변하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "418056ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 초기값을 선언하지 않는 constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93248f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. constant선언 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f2dc2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. constant를 다시 선언하더라도 shallow copy가 수행된다. (variable과 비교)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "391166dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. 동일한 값을 가지는 constant를 새로 선언하면 \n",
    "#   새로운 메모리를 할당하기 때문에 deep copy가 가능해진다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237ab06d",
   "metadata": {},
   "source": [
    "## Variable (변수)\n",
    "\n",
    "변수는 프로그램, 모델 내에서 값을 공유하는 영구적인 `상태`를 저장하는 텐서이다.  \n",
    "tensorflow, keras는 모든 가중치를 Variable으로 저장한다. 이 Variable의 특성은 아래와 같다.\n",
    "\n",
    "- tf.Variable 클래스를 통해 생성하며, 반드시 초기값이 존재해야한다.  \n",
    "    -> shape, dtype을 명시하지않아도 가능하지만 명시하는 것이 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73c62ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6027670",
   "metadata": {},
   "source": [
    "- 값이 변하지 않는다. 하지만 `assign()` method를 통해서 갱신이 가능하다.  \n",
    "    > 값이 변한 것처럼 보이지만 변경된 값으로 새로운 텐서가 만들어진 것이다. (텐서의 연산에서 설명)  \n",
    "    \n",
    "    > assign() 사용시에는 동일한 shape, dtype의 데이터로만 갱신이 가능하다.  \n",
    "    ( 새로운 텐서가 생성되는 방식이 아닌 값만 갱신되는 방식이므로 선언된 메모리의 재사용을 위해서)\n",
    "    \n",
    "\n",
    "- 프로그램 종료시점에 garbage collect(할당된 메모리를 회수하는 것)가 진행된다.   \n",
    "    > 즉, 프로그램 종료시점까지 내부의 데이터는 보존된다.\n",
    "    \n",
    "    \n",
    "    \n",
    "- name 속성값을 선언하여 해당 변수의 이름을 지정하는 것이 좋다.   \n",
    "    > 지정하지 않으면 default의 값으로 생성된다.  \n",
    "    \n",
    "    > 이 후, 디버깅이나 모델저장시 유용하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b312d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재할당을 진행하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f051fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot convert [1.0, 2.0] to EagerTensor of dtype int32 (type casting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e3c940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 덧셈을 진행하는 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23dd5d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뺼셈을 진행하는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904c34e5",
   "metadata": {},
   "source": [
    "# 1-5. 텐서의 연산\n",
    "\n",
    "텐서는 기본적으로 값이 변하지 않기 때문에 연산의 결과가 텐서에 반영되는 것이 아닌 새로운 텐서로 반환된다.   \n",
    "또한 `다차원`배열인 텐서는 기본적인 자료구조를 numpy의 구조로 사용하기 때문에 numpy의 연산과 동일하다.   \n",
    "여러가지 기본적인 연산의 예제를 통해 알아보자.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31409ed4",
   "metadata": {},
   "source": [
    "## 1. element-wise calculation\n",
    "\n",
    "numpy의 연산은 기본적으로 원소별 계산이 수행된다.  \n",
    "- numpy는  broadcasting을 지원하기 때문에 피연산자 간의 shape가 다를지라도 연산에 적합하도록 변환하여 수행한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc14c81d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f4630eb",
   "metadata": {},
   "source": [
    "- tensorflow에서도 사칙연산을 method로 제공한다. 하지만 numpy의 연산과 다르게 broadcasting이  지원되지 않으므로 피연산자간 동일한 shape가 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcf2dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9c9982a",
   "metadata": {},
   "source": [
    "## 2. matrix calculation\n",
    "\n",
    "원소별 계산이 아닌 행렬연산의 경우, tensorflow의 내장된 method를 사용한다.\n",
    "\n",
    "행렬연산이기 때문에 shape를 맞춰야 진행이 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903fbea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf24125a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a8607d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74ee5baa",
   "metadata": {},
   "source": [
    "## 3. reducer function\n",
    "\n",
    "텐서의 shape에 무관하게 데이터들을 통해 단일 값의 결과로 나오는 연산을 reducer function 이라고 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c510b128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c35f3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9db189bb",
   "metadata": {},
   "source": [
    "## 4. gradient of Variable\n",
    "\n",
    "tensorflow, keras에서는 모든 가중치의 값을 Variable에 저장한다고 하였다.   \n",
    "학습 과정에서 가중치에 대한 미분 값을 기준으로 값이 갱신되기 때문에 텐서에 대한 미분값을 계산하는 것은 매우 중요하다.   \n",
    "텐서의 미분 연산에 대한 클래스 `tf.GradientTape`를 이용하여 자동으로 미분값을 계산하고 추적하는 방법을 알아보자.  \n",
    "\n",
    "\n",
    "\n",
    "### `tf.GradientTape`\n",
    "\n",
    "생성된 객체는 `watch()` 를 통해 기록되는 텐서의 연산의 과정(연산식)을 기억해두고 `gradient()` 선언 시점에  미분값을 계산한다.\n",
    "> gradient() 를 통해 미분 연산값을 계산하고 나면 메모리에 저장되어있던 연산의 과정을 지운다. \n",
    "\n",
    "\n",
    "\n",
    "- Variable은 기본적으로 미분의 대상이기 때문에 watch() 로 선언하지 않아도 된다.\n",
    "\n",
    "\n",
    "- 미분 연산을 위해서는 반드시 dtype이 float으로 가져야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b7fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as t:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db3826",
   "metadata": {},
   "source": [
    "<img src=\"./education_images/1-1_formula.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "- 기준 변수에 대해서 파생되는 변수들에 대한 미분 값을 구하고 싶을 때 persistent=True 옵션을 사용한다.    \n",
    "    이 때는 반드시 사용된 메모리에 대한 반환을 직접 해줘야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeb65f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bb70778",
   "metadata": {},
   "source": [
    "<img src=\"./education_images/1-2_formula.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4e4bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4dfbb188",
   "metadata": {},
   "source": [
    "<img src=\"./education_images/1-3_quiz.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "1. 텐서의 제곱은 `tf.math.pow()`를 사용한다.\n",
    "2. 텐서의 루트는 `tf.math.sqrt()`를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2d2487",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(3, dtype = tf.float32)\n",
    "b = tf.constant(4, dtype =tf.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb1c272",
   "metadata": {},
   "source": [
    "#### 식으로 간단하게 미분값을 계산할 수 있는 일반 선형연산 뿐 아니라 식으로 표현이 어려운 if, for문에 대한 추적도 가능하다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f964c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "def f(x,y):\n",
    "    output = 1.0\n",
    "    for i in range(y):\n",
    "        if i > 1 and i < 5:\n",
    "            output = tf.multiply(output, x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dcfd4e",
   "metadata": {},
   "source": [
    "# Graph\n",
    "\n",
    "지금까지 배운 것을 잠깐 정리해보면,\n",
    "\n",
    "1. 텐서는 값의 변경이 불가능하다. ( tf.Variable 으로 선언된 변수의 경우, 값의 갱신이 가능하였다.)\n",
    "\n",
    "2. 1번의 특성으로 인해 모든 텐서 간의 연산은 값의 변경이 아닌 연산 결과값을 가진 텐서가 새롭게 생성되는 방식이다.\n",
    "\n",
    "이러한 특성으로 우리는 (피연산자 - 연산자 - 연산의 결과값)에 해당하는 모든 연산의 과정을 텐서로 표현할 수 있는데 연산의 과정을 텐서로 표현한 것이 바로 `Graph`이다. 아래의 간단한 예제 들을 보고 그래프의 개념을 이해해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48383a83",
   "metadata": {},
   "source": [
    "<img src=\"./education_images/1-4_formula.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced14db6",
   "metadata": {},
   "source": [
    "<img src=\"./education_images/1-5_graph.png\" alt=\"Drawing\" style=\"width: 100px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d97c49",
   "metadata": {},
   "source": [
    "2.0 이전의 버전의 tensorflow는 내부적으로 모든 연산에 대해서 그래프를 구현한 뒤,  `Lazy evaluation`으로 연산을 수행한다. \n",
    "\n",
    "> `Lazy evaluation`이란, 연산의 결과값이 필요할 때까지 연산을 실시하지 않고 미뤄두었다가 연산값이 호출되는 시점에 연산을 실시하는 기법이다.\n",
    "\n",
    "\n",
    "  즉, 텐서로 연산을 수행하는 코드를 작성하고 실행한다고 해서 연산이 수행되는 것이 아니라 단순히 연산의 그래프를 그리는 행위일 뿐, 실제 연산의 수행은 연산값을 호출할 때 이루어진다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c60881",
   "metadata": {},
   "source": [
    "### 1. 프로그램이 실행되면 연산의 과정에 따라 텐서들을 연결하여 그래프로 만든다.  \n",
    "\n",
    "- 이시점에서 연산의 최적화가 발생한다. 연산이 복잡하고 많을수록 더 많은 개선이 일어난다.\n",
    "- 내부 연산을 분할하여 병렬처리가 가능하도록 구현\n",
    "- 연산을 단순화하도록 구현\n",
    "\n",
    "### 2. 하나의 그래프가 수행되는 절차 단위인 session은 그래프를 device 상에서 수행될 수 있도록 C코드로 변환한다.\n",
    "\n",
    "- CPU, GPU에서 수행될 수 있도록 device에 대해 최적화를 진행한다.\n",
    "- C 코드로 수행하기 때문에 python의 속도의 한계를 극복할 수 있게 된다.\n",
    "- python 인터프리터에 대한 환경의 제약조건이 사라지게 되면서 배포환경에 대해 자유롭다.\n",
    "\n",
    "\n",
    "### 3. `run()` 코드를 통해 연산값을 호출하면 연산을 수행하고 결과값을 반환한다.\n",
    "\n",
    "연산을 즉시 수행하는 것이 아닌 최대한 늦추는 기법을 사용하게 되면서, 내부 연산에 대한 최적화, device에 대한 최적화, 속도 개선등의 이점을 얻을 수 있었다. 하지만 연산에 대한 결과값을 즉시 볼 수 없기 때문에 디버깅하기 어렵고, 연산이 즉시 수행되는 `Eager evaluation`에 익숙해져있는 개발자들의 생산성이 떨어질 수 밖에 없었다. 때문에 Tensorflow 2.0에서는 그래프를 사용하지 않고 연산의 결과값을 코드 실행시점에 즉시 볼 수 있도록  `Eager evaluation`을 채택하였다. 그럼에도 불구하고 연산 및 학습의 속도를 위해 데코레이터를 통해 연산의 과정을 그래프로 만들어 수행하는 기능도 제공하고 있다. 데코레이터를 활용한 간단한 예제를 살펴보자.\n",
    "\n",
    "\n",
    "- 데코레이팅 된 함수 내에서 호출된 함수 또한 그래프의 대상이 된다.\n",
    "\n",
    "\n",
    "-  우리가 사용하는 함수를 단순히 데코레이터로 래핑하는 것만으로도 속도를 높일 수 있다. 하지만 복잡하지 않은 계산에 대해서는 오히려 그래프 및 그래프 조각호출에 사용하는 시간이 더 많을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc35e810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_function(x, y, b):\n",
    "    x = tf.matmul(x,y)\n",
    "    x = x + b\n",
    "    return x\n",
    "\n",
    "@tf.function\n",
    "def outer_function(x):\n",
    "    y = tf.constant([[2.0], [3.0]])\n",
    "    b = tf.constant(4.0)\n",
    "    \n",
    "    return inner_function(x, y, b)\n",
    "\n",
    "outer_function(tf.constant([[1.0, 2.0]])).numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
