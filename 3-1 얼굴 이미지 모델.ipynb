{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cbcdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42b95a2",
   "metadata": {},
   "source": [
    "# CNN  기본 구현하기\n",
    "\n",
    "## 모델 구조\n",
    "\n",
    "convolution -> batch -> activation -> maxpooling -> fully-connected -> softmax\n",
    "\n",
    "\n",
    "- input layer에서 부터 output layer까지 하위 - 상위 layer로 부른다.  \n",
    "    \n",
    "    또한 상위로 갈수록 layer의 결과값인 feature map의 크기는 줄어들고, channel의 수는 증가한다. 이 때, 각 layer의 feature map의 크기와 channel의 수는 우리가 조절해야하는 파라미터이다. 그렇다면 이 파라미터를 어떻게 조정하는 것이 좋을까?\n",
    "    \n",
    "\n",
    "- 각 레이어의 계산 복잡도(연산의 양)을 균일하게 하기 위하여 layer의 결과값인 feature map의 크기와 그 갯수인 channel의 수의 곱이 반드시 동일하게 유지되어야 한다.  \n",
    "    \n",
    "    예를 들면 layer의 출력 image의 사이즈가 2배 줄어들었다면 channel의 수는 반드시 2배로 증가해야한다. 하지만 증감에 대한 가이드만 존재할 뿐 얼마나 변경되어야하는지는 논문마다, 데이터 셋마다 다르다.   \n",
    "    \n",
    "    하지만 거의 대부분이 layer를 거치면서 feature map의 크기는 2배로 감소하고 channel의 수는 2배 증가한다.\n",
    "    \n",
    "- filter의 크기는 데이터 셋을 기반으로 선택한다.\n",
    "\n",
    "    데이터 셋에 대한 overfitting이 발생하지 않도록 하는 적절한 수준을 찾아야한다. \n",
    "    \n",
    "    \n",
    "- pooling은 주로 max pooling이 사용된다. \n",
    "    \n",
    "    stride가 2, filter의 크기는 2X2가 사용된다. 이 때, filter의 크기는 4이상은 정보의 손실이 과도하게 발생할 수 있기 때문에 거의 사용하지 않는다. ~~하지만 resnet에서는..~~\n",
    "\n",
    "\n",
    "- down sampling을 사용할 때, 정보의 손실을 최소화한다고 하더라도 반드시 손실은 발생할 수 밖에 없다.\n",
    "\n",
    "    fully connected layer을 사용한다고 하더라도 모든 node를 사용하는 것임에도 input - output간의 변동이 발생한다.    \n",
    "    \n",
    "    pooling의 과정은 down sampling의 과정을 하기 위함인데, 이 과정을 수행하지 않고 마지막 fully connected layer 대신, global average pooling을 사용하는 방법이 있다.\n",
    "    \n",
    "- 과적합을 방지하는 방법에는 여러가지가 있으나 우리가 할 수 있는 것들은 dropout을 사용하거나 parameter의 수를 줄이는 방법등이 있다.\n",
    "\n",
    "    dropout은 fully connected layer의 사이에서 학습과정에서 사용되는 connected node의 수를 임의적으로 줄여 과적합을 방지한다. 모든 트레이닝 데이터에 대해서 모든 node를 사용하는 것을 방지함으로써 과적합을 방지한다.이 과정을 통해 데이터 셋에 민감하지 않은 robust한 모델을 구현하는데 새로운 데이터를 만드는 것보다 훨씬 효율적이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a1d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8a42259",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7edb454d8c03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#이미지 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "#이미지 확인\n",
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6841bc2c",
   "metadata": {},
   "source": [
    "## 데이터가 이미지가 2차원 배열임을 알 수 있다.\n",
    "\n",
    "channel의 shape를 추가해준다. 이미지가 channel이라는 차원도 존재하기 때문에 3차원으로 만들어준다. \n",
    "\n",
    "1. shape는 tuple로 반환된다.\n",
    "2. tuple간의 덧셈이 가능하다.\n",
    "3. tuple을 선언하는 방법은 ()으로 감싸면 된다. 하지만 하나의 원소를 가질 때는 ,를 뒤에 붙여서 iterable하게 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1a81c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca521178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53b8e420",
   "metadata": {},
   "source": [
    "# 단순한 CNN 구조의 모델 구현\n",
    "\n",
    "일반적으로 각 layer의 shape에서 이미지의 높이, 너비를 나타내는 1,2번째 shape는 pooling과정에 의해 줄어든다.   \n",
    "우리가 이전 과정을 통해 convolution layer의 output을 feature map이라고 하였기 때문에 feature map의 크기가 줄어든다고 할 수 있다.\n",
    "\n",
    "- feature map의 크기가 줄어들었기 때문에 이에 맞게 filter의 갯수 또한 2배로 늘리는 작업을 수행하여 연산의 복잡도를 유지한다.\n",
    "\n",
    "- 반복작업에 대해서는 하나의 layer를 만들어서 모델 선언영역을 최소화할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a46986b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad88ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bfa001a",
   "metadata": {},
   "source": [
    "## compile\n",
    "API로 작성된 model의 학습에 필요한 파라미터를 설정한다. \n",
    "\n",
    "1. adam -> 주로 사용되는 옵티마이저이다. 여러가지 옵타마이저 중에서 수렴속도가 빠른편에 속한다.\n",
    "2. sparse_categorical_crossentropy -> 결과값이 integer인 경우 사용한다. \n",
    "\n",
    "loss function에서 각 category의 확률로 반환되는 모델의 예측값과의 차이를 계산할 때 \n",
    "- integer\n",
    "- one-hot encoding의 array  \n",
    "\n",
    "인지에 따라 다르다.\n",
    "\n",
    "categorical_crossentropy와 동일하게 다중분류 시에 사용하는 loss function이다. \n",
    "하지만 차이점은 categorical_crossentropy의 경우, 결과값이 one-hot encoding이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02dc557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b39f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b32e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b09e441b",
   "metadata": {},
   "source": [
    "\n",
    "- 이미지를 확대하는 경우, 바이큐빅 보간법이나 쌍 선형 보간법을 가장 많이 사용합니다.\n",
    "- 이미지를 축소하는 경우, 영역 보간법을 가장 많이 사용합니다.\n",
    "\n",
    "\n",
    "## 평가\n",
    "\n",
    "실제 손글씨에 대한 예측이 올바르게 수행되고 있는 가에 대해서 확인하고자 합니다. 전처리를 하기 위해서 OpenCV를 사용합니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95afcf08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c59b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a812a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672ea56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "660eb353",
   "metadata": {},
   "source": [
    "# 얼굴 표정을 이진 분류하는 모델\n",
    "\n",
    "CNN을 맛보기 위해 간단한 모델 구현\n",
    "\n",
    "- ImageDataGenerator 사용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba559cf8",
   "metadata": {},
   "source": [
    "# 데이터 준비 \n",
    "\n",
    "###  디렉토리 구조를 통해서 데이터셋을 가져온다.\n",
    "\n",
    "```\n",
    "/basedata\n",
    "    /train  \n",
    "        /happy  \n",
    "        /unhappy   \n",
    "    /test  \n",
    "        /happy  \n",
    "        /unhappy\n",
    "    /validation\n",
    "        /happy  \n",
    "        /unhappy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f8bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a22d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a370eba",
   "metadata": {},
   "source": [
    "# 모델 정의\n",
    "\n",
    "https://keras.io/api/layers/convolution_layers/convolution2d/\n",
    "\n",
    "1. Conv2D\n",
    "\n",
    "```python \n",
    "tf.keras.layers.Conv2D(\n",
    "    filters,\n",
    "    kernel_size,\n",
    "    strides=(1, 1),\n",
    "    padding=\"valid\",\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    groups=1,\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer=\"glorot_uniform\",\n",
    "    bias_initializer=\"zeros\",\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    **kwargs\n",
    ")\n",
    "```\n",
    "\n",
    "2. MaxPool2D\n",
    "\n",
    "```python\n",
    "tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2), strides=None, padding=\"valid\", data_format=None, **kwargs\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "3. relu\n",
    "\n",
    "\n",
    "```python\n",
    "tf.keras.layers.ReLU(max_value=None, negative_slope=0, threshold=0, **kwargs)\n",
    "```\n",
    "\n",
    "\n",
    "4. sigmoid\n",
    "\n",
    "```python\n",
    "tf.keras.layers.Activation(tf.keras.activations.sigmoid)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a0d149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f45db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e75354bf",
   "metadata": {},
   "source": [
    "# TFhub 를 사용한 전이학습\n",
    "\n",
    "물체를 인식하는 데이터셋 모델을 사용해서 표정인식을 해보았다.\n",
    "> 파인튜닝을 진행해보았지만 여전히 정확도가 낮았다.\n",
    "\n",
    "> 매우 좋지 않은 모델이 탄생했다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
