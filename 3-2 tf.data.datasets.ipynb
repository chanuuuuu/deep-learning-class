{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e3a6fcfbbfb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#!pip install tensorflow-datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow-datasets\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.keras.datasets 를 통해 데이터 들고오기\n",
    "\n",
    "### 1. mnist\n",
    "\n",
    "손글씨 그림으로 기존의 모델을 구현할 때 사용하였던 데이터들이다.\n",
    "\n",
    "- 60000개의 28X28 크기의 이미지\n",
    "- 10개의 class\n",
    "- grayscale으로 채널의 크기가 1이다.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "    tf.keras.datasets.mnist.load_data(\n",
    "        path='mnist.npz'\n",
    "    )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. fashion_mnist\n",
    "\n",
    "zalando라는 패션 회사의 제품 이미지 데이터\n",
    "\n",
    "- 60000개의 28X28 크기의 이미지\n",
    "- 10개의 class\n",
    "\n",
    "```python\n",
    "    tf.keras.datasets.fashion_mnist.load_data()\n",
    "```\n",
    "\n",
    "패션 데이터의 라벨 및 자세한 정보는 아래의 링크에서 확인할 수 있다.  \n",
    "https://github.com/zalandoresearch/fashion-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. cifar10\n",
    "\n",
    "### 4. cifar100\n",
    "\n",
    "물체 분류 데이터셋으로, 클래스의 갯수에 따라 10, 100으로 나뉜다.\n",
    "\n",
    "- 50000장의 32X32의 컬러 이미지 데이터\n",
    "- y의 값은 (num_samples, 1)의 shape를 가진다. 즉, 하나의 이미지마다 scalar값이 아니라 1의 길이를 갖는 배열이다.\n",
    "\n",
    "자세한 데이터는 아래의 링크로 확인 가능하다.  \n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로컬 디렉토리를 통한 데이터 셋 구성\n",
    "\n",
    "\n",
    "# 데이터셋 클래스 객체에 대한 여러가지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.microsoft.com/en-us/download/details.aspx?id=54765\n",
    "\n",
    "# image_dataset_from_directory\n",
    "\n",
    "```python\n",
    "tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    ")\n",
    "```\n",
    "\n",
    "## returns\n",
    "\n",
    "tf.data.Dataset의 타입으로 데이터셋을 구성하여 반환한다. 이때, 데이터셋은 아래의 파라미터들을 통해 구성된다.\n",
    "\n",
    "\n",
    "### label_mode\n",
    "\n",
    "1. int\n",
    "> 카테고리의 값을 정수로 변환하여 전달한다.  \n",
    "> sparse_categorical_crossentropy  \n",
    "> label의 경우,(batch_size, )의 shape를 가진다.\n",
    "\n",
    "2. categorical\n",
    "> 카테고리의 값을 디렉토리의 이름으로 전달한다.-> one-hot encoding된 상태로 전달한다.  \n",
    "> categorical_crossentropy  \n",
    "> label의 경우,(batch_size, num_classes)의 shape를 가진다. \n",
    "\n",
    "3. binary\n",
    "> 카테고리를 이진 값으로 변환하여 전달한다. -> float32으로 사용  \n",
    "> binary_cross_entropy  \n",
    "> label의 경우,(batch_size, 1)의 shape를 가진다.\n",
    "\n",
    "\n",
    "### color_mode\n",
    "\n",
    "1. 'rgb'\n",
    "2. 'grayscale'\n",
    "\n",
    "\n",
    "\n",
    "### batch_size\n",
    "말그대로 배치 사이즈, 배치 사이즈란, 1회의 수행 동안에 사용할 데이터의 크기를 말한다.   \n",
    "이 크기 만큼 한번 돌기 때문에 도는 횟수는 N / batch_size 이겠죠?\n",
    "\n",
    "\n",
    "### validation_split\n",
    "0,1 사이의 실수값으로 validation set을 구성할 것인가를 결정한다.\n",
    "\n",
    "### subset\n",
    "위의 validation_split을 사용한 경우, training, validation 두가지의 subset이 나오기 때문에 해당 파라미터로 구분한다.\n",
    "\n",
    "### seed\n",
    "난수를 생성하기 위해 필요한 seed값을 전달한다. 이 때, 동일한 조건의 training, validation을 사용하기 위해서 반드시 명시하여줘야한다.\\\n",
    "\n",
    "\n",
    "\n",
    "### interpolation\n",
    "image resizing할 때, 픽셀값의 변화를 어떻게 적용할 것인가에 대한 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 저장시의 에러 처리\n",
    "import os\n",
    "\n",
    "num_skipped = 0\n",
    "for folder_name in (\"Cat\", \"Dog\"):\n",
    "    # 이부분 반드시 변경이 필요하다.\n",
    "    folder_path = os.path.join(\"pets\", folder_name)\n",
    "    for fname in os.listdir(folder_path):\n",
    "        fpath = os.path.join(folder_path, fname) # PetImages/Cat/63.jpg\n",
    "        try:\n",
    "            fobj = open(fpath, \"rb\")\n",
    "            # fobj.peek(10)은 10바이트를 가져오는데, 여기서는 보통\n",
    "            # 헤더를 읽기 위해 전체를 가져온다고 생각해도 무방합니다.\n",
    "            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
    "        finally:\n",
    "            fobj.close()\n",
    "        \n",
    "        # JFIF의 헤더를 들고 있지 않으면 손상된 파일이므로 삭제    \n",
    "        if not is_jfif:\n",
    "            num_skipped += 1\n",
    "            os.remove(fpath)\n",
    "print(num_skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load_img  \n",
    "\n",
    "image 파일을 PIL객체로 만들어준다. \n",
    "\n",
    "```\n",
    "tf.keras.preprocessing.image.load_img(\n",
    "    path, grayscale=False, color_mode=\"rgb\", target_size=None, interpolation=\"nearest\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIL -> numpy array\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.data.Dataset\n",
    "\n",
    "매우 큰 데이터에 대해서 입력의 파이프라인을 구축한다. 데이터 변환, 전처리등의 작업을 편하게 할 수 있도록 하는 API이다.\n",
    "\n",
    "\n",
    "- batch size를 정의하게 되면, batch size만큼의 하나의 element로 저장된다. 정의하지 않아도 32가 기본적으로 사용된다.  \n",
    "\n",
    "\n",
    "- cardinality, 차수를 통해 batch의 갯수를 확인할 수 있다.  \n",
    "\n",
    "\n",
    "- dataset의 경우, for loop / as_numpy_iterator()를 사용하는 경우를 제외하고 모든 원소가 tensor이다.\n",
    "\n",
    "\n",
    "- tf.py_function()을 이용하여 작업을 그래프화하여 하는 경우, 성능상의 이득을 얻을 수 있다.(최적화는 공부 범위 밖)\n",
    "\n",
    "```python\n",
    "#py_function으로 graph화하기\n",
    "train_dataset.take(1).map(\n",
    "    lambda images, labels : tf.py_function(batch_func, [images, labels], [tf.float32, tf.float32]))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take()\n",
    "\n",
    "- 원소하나를 들고온다. == batch 한 개를 들고온다고 생각하면 된다.\n",
    "\n",
    "\n",
    "- BatchDataset -> TakeDataset으로 변환된다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply()\n",
    "\n",
    "각 batch size의 dataset에 대해서 함수를 적용한다.\n",
    "\n",
    "\n",
    "## as_numpy_iterator()\n",
    "\n",
    "numpy 배열로 변환한다.\n",
    "\n",
    "\n",
    "## batch()\n",
    "\n",
    "batch_size만큼 잘라낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flat_map\n",
    "\n",
    "- batch의 개념없이 모든 원소에 대해서 직접 접근, flatten과정 수행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from_tensor_slices()\n",
    "\n",
    "dictinary 형태, tuple형태의 데이터에 대해서 dataset을 구성하고자할 떄, 유용하게 사용할 수 있는 함수이다.\n",
    "\n",
    "\n",
    "## tf.data.Dataset.zip()\n",
    "\n",
    "데이터의 형태가 모두 tf.data.Dataset일 경우, zip()을 사용하여 하나의 dataset으로 바꾼다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## enumerate()\n",
    "\n",
    "python의 함수와 동일한 기능을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map()\n",
    "\n",
    "dataset의 원소마다 함수를 수행할 수 있도록 하는 함수\n",
    "\n",
    "#### map 을 사용하는 이유\n",
    "\n",
    "데이터를 로드하는 과정과 병렬처리를 최적화할 수 있기 때문에 사용하는 것이 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reduce\n",
    "\n",
    "모든 원소에 대해서 함수를 수행하여 단일 값으로 반환하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shuffle\n",
    "\n",
    "말 그대로 섞는다. 이 때, buffer_size를 인자로 전달해야하는데 이 값은 반드시 전체 sample size보다는 크거나 같아야한다.\n",
    "shuffle의 대상의 크기를 정하는 것이므로, 대상이 되지 않는 sample에 대해서는 섞이지 않는 문제가 발생할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실제 데이터에 응용해보기\n",
    "\n",
    "`image_dataset_from_directory`을 사용하여 이미지 데이터를 로드할 수 있다. 특정 디렉토리 내에 레이블에 따라 디렉토리로 구분되어있어야한다. 하지만 대부분의 망할 데이터는 편안한 형태로 제공되지 않는다. 이런 경우에는 어떻게 데이터 셋을 구현할 것인가에 대해 생각해보자.\n",
    "\n",
    "### 목적\n",
    "레이블마다 다른 디렉토리 경로의 데이터들을 어떻게 취합하여 사용할 것인가? \n",
    "\n",
    "\n",
    "### 문제\n",
    "\n",
    "1. `image_dataset_from_directory`의 경우, 반드시 디렉토리로 레이블이 구분되어있어야한다. 이러한 제약조건을 이길 수 있는 방법은 없을까?\n",
    "    > tf.data.Dataset을 레이블마다 구현하여 파이프라인을 커스터마이징하여 결합한다.\n",
    "    \n",
    "2. 이미지가 구분되어있을 때, 레이블링은 어떻게 할 것인가?\n",
    "    > 동일 디렉토리가 아닌 경우, 디렉토리명으로 구분하여\n",
    "    \n",
    "3. 이미지가 구분되어있지 않을 때 레이블링은 어떻게 할 것인가? \n",
    "    > 동일 디렉토리에 존재하는 경우에는 이름으로 구분하여 \n",
    "\n",
    "\n",
    "### 해결책\n",
    "\n",
    "1. `tf.data.Dataset.list_files` 을 사용하여 file list를 load한다. (file load pipeline)\n",
    "2. file name만 가진 dataset 이기 때문에 해당 file name을 통해 image를 load하는 파이프라인을 구축한다.\n",
    "3. file name을 통해 해당 이미지가 어떤 레이블인지를 판단한다.\n",
    "\n",
    "\n",
    "### 필요한 함수들\n",
    "\n",
    "\n",
    "#####  `tf.io.read_file()`\n",
    "\n",
    "input pipeline의 맨처음으로, filename을 인자로 받아 해당 파일의 컨텐츠를 받아온다.   \n",
    "이 때, 파일의 format에 대한 제약조건은 존재하지 않는다.  \n",
    "이미지의 경우, encoding된 'text' 타입의 content를 저장한 tensor를 반환한다.  \n",
    " \n",
    "\n",
    "#####  `tf.io.decode_png()`\n",
    "\n",
    "image content가 담긴 tensor를 인자로 받아 decoding하여 uint8인 np.array로 바꾸어준다.   \n",
    "\n",
    "> 이 때, uint8은 2의 8승이 256이기 때문에 0-255의 int의 값을 말한다.\n",
    "\n",
    "\n",
    "##### `tf.string.split()`\n",
    "\n",
    "image의 path를 통해서 레이블을 설정하기 위해 path를 쪼개기 위해 사용한다.  \n",
    "이 때, path는 'string' type의 tensor이기 때문에 일반적으로 string의 split을 사용이 불가능하기 때문에 사용한다.\n",
    "\n",
    "\n",
    "##### `tf.cast()`\n",
    "\n",
    "tensor의 dtype을 변경하기 위해서 사용한다.   \n",
    "numpy의 array의 경우에는 astype()을 사용할 수 있으나 tensor이기 떄문에 대신하여 사용한다.  \n",
    "\n",
    "##### `cardinality()`\n",
    "\n",
    "'차수'라는 개념인데, dataset에서 data의 갯수를 의미한다.\n",
    "- 이 때, 중복의 유무에 따라 달라진다. 중복이 존재하는 경우 1개로 판단하기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 저장\n",
    "\n",
    "열심히 만든 이미지에 대해서 저장이 하고 싶을 수 있다. 이럴 때 저장하는 과정을 만들어두자.\n",
    "\n",
    "- image resizing을 진행하고 나면 dtype이 float32이다. 해당 dtype으로는 image encoding이 불가하므로 uint8으로 변경해줘야한다.\n",
    "- 가끔씩 이미지 전부가 검은색으로 나오는 경우가 있다. 이 경우는 0-255까지의 값을 가지는 uint8이 아니라 0-1의 값을 가지는 uint8이기 때문에 모든 픽셀값이 0에 가까워 어둡게 보이는 것이다.\n",
    "\n",
    "## 구현방법\n",
    "\n",
    "1. map을 통한 구현을 진행  \n",
    "    > map() 의 경우 자체적으로 graph mode로 연산을 수행한다. 이 때, 연산의 최적화를 위해 모든 과정에 대한 vectorization 수행  \n",
    "    > 또한 map은 dataset을 반환하는 작업으로, 전처리를 통해 새로운 dataset을 만들 때 사용한다.\n",
    "    \n",
    "2. image를 저장하는 작업의 경우, vectorization이 되지 않는 부분이 존재한다.\n",
    "    > `unbatch()` 를 통해 반복 수행을 진행할 수 있도록 변환하여 for 문을 통해 원소별 수행\n",
    "    > 이 작업은 매우 비효율적임. __(가급적 하지 않는 것이 좋다.)__\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
