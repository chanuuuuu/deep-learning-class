{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN의 기본 개념\n",
    "\n",
    "\n",
    "## Convolution Layer\n",
    "\n",
    "이미지를 입력으로 받아 이미지 내의 '특징들을 검출'하는 역할\n",
    "\n",
    "컨볼루션 레이어의 Output을 우리는 'feature map'이라고 한다.  -> 컨볼루션의 결과 값이 이미지가 가지고 있는 특징을 의미한다고 볼 수 있다.\n",
    "\n",
    "\n",
    "### 1. kernel(filter)\n",
    "\n",
    "컨볼루션 연산을 통해 이미지 내의 특징들을 '기억'하는 가중치 텐서\n",
    "\n",
    "\n",
    "이미지들의 공통적인 특징들을 kernel이 기억하고 있다가 해당 공통적인 특징을 통해 검출된 이미지의 특징을 레이어의 출력인 feature map이라고 한다.\n",
    "\n",
    "\n",
    "kernel size 3X3, 5X5로 홀수의 크기를 가지며, 크기가 클수록 더 큰 범위, 크기의 특징들을 기억한다.\n",
    "\n",
    "\n",
    "레이어의 Output인 출력 텐서의 마지막 차원의 크기는 해당 컨볼루션 레이어가 가진 필터(커널)의 수가 된다.\n",
    "\n",
    "\n",
    "(128, 128, 3)의 크기의 이미지가 들어올 때, 컨볼루션 레이어가 가지는 필터의 수가 64라면, 레이어의 Output의 shape(~, ~, ~, 64)가 된다.\n",
    "\n",
    "\n",
    "\n",
    "### 2. stride\n",
    "\n",
    "컨볼루션 연산을 수행하는 커널이 이미지를 얼마나 자세하게 볼 것인가를 결정하는 값. 커널은 공통적인 특징을 기억을 했다가 입력으로 들어오는 이미지의 특징을 반환한다고 설명했다. 특징들을 얼마나 세세하게 검출해낼 것인가를 결정하는 것과 동일한 의미를 가진다.\n",
    "\n",
    "\n",
    "컨볼루션 연산의 결과인 feature map의 크기를 결정할 수 있다.\n",
    "\n",
    "\n",
    "### 3. padding\n",
    "\n",
    "컨볼루션 연산의 결과인 feature map의 크기를 결정하기 위해 사용되는 값\n",
    "\n",
    "\n",
    "'valid' - padding을 사용하지 않는다.\n",
    "\n",
    "\n",
    "'same' - 컨볼루션 레이어의 Input shape, Output shape를 동일하게 하기위해 패딩을 추가한다.\n",
    "\n",
    "\n",
    "## Keras를 통한 Convolution Layer 구현\n",
    "\n",
    "\n",
    "Dense() -> fully connected layer를 구현하지 않아도 사용할 수 있었다.\n",
    "\n",
    "Conv2D() -> convolution layer를 미리 구현하여 사용할 수 있도록 제공\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "tf.keras.layers.Conv2D(\n",
    "    filters,\n",
    "    kernel_size,\n",
    "    strides=(1, 1),\n",
    "    padding=\"valid\",\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    groups=1,\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer=\"glorot_uniform\",\n",
    "    bias_initializer=\"zeros\",\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "- filters\n",
    "\n",
    "\n",
    "    커널의 갯수 -> 해당 컨볼루션 레이어의 마지막 차원의 크기 64 -> output shape (~, ~, ~, 64)\n",
    "\n",
    "\n",
    "- kernel_size\n",
    "\n",
    "\n",
    "    커널의 크기 -> 3X3, 5X5 정수값으로 사용합니다. 예를 들어 kernel_size = 3이라면  실제 커널의 사이즈 (3,3)일 것이다.\n",
    "\n",
    "\n",
    "- strides\n",
    "\n",
    "    stride의 값을 나타낸다. 기본값은 (1, 1), 정수값을 사용할 수 있다.\n",
    "    \n",
    "\n",
    "- padding\n",
    "\n",
    "\n",
    "    'valid', 'same' 두가지 옵션이 존재한다. \n",
    "\n",
    "\n",
    "- activation\n",
    "\n",
    "    컨볼루션 레이어의 최종적인 결과인 Output에 대해서 활성화 함수를 거친뒤 반환할 것인가에 대해서 결정합니다.\n",
    "\n",
    "    activation = 'relu'으로 사용시, 컨볼루션 연산을 수행한 결과값에 대해서 relu 활성화 함수를 거친 최종 값을 해당 레이어의 결과값으로 반환합니다.\n",
    "\n",
    "    옵션을 통해서 컨볼루션 레이어에 끝에 활성화 함수를 추가할 수 있으나 여러 논문에서는 활성화 함수 레이어를 따로 구현하여 사용합니다.\n",
    "\n",
    "\n",
    "\n",
    "## Activation Layer\n",
    "\n",
    "\n",
    "컨볼루션 레이어의 결과인 feature map(이미지 내의 특징)에 대해서 활성화 함수를 거치기 위해서 컨볼루션 레이어 뒤에 추가하는 레이어\n",
    "\n",
    "\n",
    "컨볼루션 - () - activation layer 의 순서는 거의 사실상 하나의 레이어라고 볼 수 있습니다.\n",
    "\n",
    "\n",
    "선형적인 convolution 연산과정을 수행하는 convolution layer에 대해서 여러 층을 쌓는 효과를 위해 해당 연산들 사이에 비 선형성을 추가하는 함수\n",
    "\n",
    "선형적인 함수들의 연속에서는 연속된 함수들이 하나의 함수로 표현될 수 있습니다. \n",
    "\n",
    "-> 여러 층을 쌓는 효과가 없어지게 된다. 하지만 딥러닝을 사용하는 이유가 선형적인 모델이 풀 수 없는 문제들을 풀어내기위해 사용하는 것이기 때문 \n",
    "\n",
    "-> 비선형성을 추가함으로써 선형 함수들이 할 수 없는 것들을 해낼 수 있게 된다.\n",
    "\n",
    "\n",
    "### relu\n",
    "\n",
    "\n",
    "### sigmoid\n",
    "\n",
    "\n",
    "## MaxPooling Layer\n",
    "\n",
    "풀링 레이어의 한 종류, 주로 사용되는 풀링 레이어\n",
    "\n",
    "컨볼루션 레이어의 결과인 이미지 내의 특징들을 '종합'하는 함수\n",
    "\n",
    "\n",
    "이미지의 입력(개, 고양이 사진)에서부터 최종적인 분류 출력값(0, 1)을 나타내기위해 필요한 차원축소를 수행\n",
    "\n",
    "\n",
    "특징들 중에서도 더 중요한 특징들로 간추리기 위한 연산과정이다.\n",
    "\n",
    "\n",
    "```python\n",
    "tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2), strides=None, padding=\"valid\", data_format=None, **kwargs\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "\n",
    "기존 이미지 데이터의 픽셀 값은 [0-255]의 값을 가진다. [0-1]사이의 데이터로 변환하는 작업은 수행해줘야 한다. 대신 배열형태로 변환했던 과정은 생략합니다.\n",
    "\n",
    "CNN을 구현할 때, 원래 이미지는 3차원의 행렬형태 입니다. (이미지의 너비, 이미지의 높이, 이미지의 채널 수) 3개의 차원으로 이미지를 표현하는데, MNIST의 경우에는 현재 2차원의 행렬형태입니다. (이미지의 너비, 이미지의 높이)이기 때문에 채널 수라는 하나의 차원을 추가해줘야 한다.\n",
    "\n",
    "\n",
    "- 채널이 존재하지 않는다는 것은 해당 이미지가 흑백이라는 뜻 <-> 3-4개의 채널을 가지면 해당 이미지는 컬러이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행렬 형태의 이미지를 배열 형태의 이미지로 변환하는 작업\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 튜플 간의 덧셈\n",
    "x_train.shape + (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차원을 하나 추가\n",
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "x_test = x_test.reshape(x_test.shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이미지로 다루기 위해서 차원을 1개 추가하였다.\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 구현 방법\n",
    "\n",
    "\n",
    "\n",
    "convolution layer -> activation layer -> max pooling layer \n",
    "\n",
    "-> convolution layer -> activation layer -> max pooling layer \n",
    "\n",
    "-> convolution layer -> activation layer -> max pooling layer\n",
    "\n",
    "-> flatten ->  fully connected layer -> 결과값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential API로 CNN을 구현해보자.\n",
    "\n",
    "\n",
    "seq_model = tf.keras.models.Sequential([\n",
    "    \n",
    "    # 32는 필터의 갯수, (3,3)은 필터의 크기\n",
    "    # 데이터 하나의 shape를 의미합니다.\n",
    "    #  (input_shape - filter + (padding * 2)) / stride + 1 \n",
    "    # (28 - 3) / 1  + 1 = 26_\n",
    "    # 최종적인 레이어의 output shape (None, 26, 26, 32)\n",
    "    tf.keras.layers.Conv2D(32, (5,5), input_shape = (28, 28, 1)),\n",
    "    \n",
    "    # activation function \n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    # stride가 2이다. \n",
    "    #  (input_shape - filter + (padding * 2)) / stride + 1 \n",
    "    # (26 - 2) / 2  + 1 =  13 \n",
    "    # 최종적인 레이어의 output shape (None, 13, 13, 32)\n",
    "    tf.keras.layers.MaxPooling2D(2),\n",
    "    \n",
    "    # 이미지의 크기가 26 -> 13으로 줄어들게 되면 모델이 파악할 수 있는 정보의 크기가 절반으로 줄어든다.\n",
    "    # maxpooling을 거친 뒤에 output shape가 절반으로 줄어들기 때문에 그만큼 filter수를 2배 증가시켜줘야합니다.\n",
    "    tf.keras.layers.Conv2D(64, (5,5)),\n",
    "    \n",
    "    # activation function \n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    # stride가 2이다.\n",
    "    tf.keras.layers.MaxPooling2D(2),\n",
    "    \n",
    "    # Flatten을 통해서 fully connected layer의 입력으로 들어갈 수 있도록 배열의 형태로 변환한다.\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # output shape의 크기는 대부분 짝수\n",
    "    tf.keras.layers.Dense(64),\n",
    "    \n",
    "    # activation function \n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    # 최종적인 결과값이 0-9사이의 정수값으로 손글씨를 분류하는 것이기 때문에 \n",
    "    # softmax란, 각 10개의 output shape를 가지는 출력값을 확률값으로 변환하는 과정\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 118,346\n",
      "Trainable params: 118,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile을 통한 학습 루프 정의\n",
    "\n",
    "seq_model.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1423 - accuracy: 0.9559\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0437 - accuracy: 0.9865\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0299 - accuracy: 0.9907\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0229 - accuracy: 0.9928\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0169 - accuracy: 0.9949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b9b3a1f340>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "seq_model.fit(x_train, y_train, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0421 - accuracy: 0.9879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04214546084403992, 0.9879000186920166]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기존의 모델 다른 방식으로 구현해보기\n",
    "\n",
    "\n",
    "## functional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential API로 CNN을 구현해보자.\n",
    "inputs = tf.keras.layers.Input(shape = (28, 28, 1))\n",
    "\n",
    "x = tf.keras.layers.Conv2D(32, (5,5))(inputs)\n",
    "\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "x = tf.keras.layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(64, (5,5))(x)\n",
    "\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "x = tf.keras.layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(64)(x)\n",
    "\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "y = tf.keras.layers.Dense(10, activation = 'softmax')(x)\n",
    "\n",
    "func_model = tf.keras.Model(inputs = inputs, outputs = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 118,346\n",
      "Trainable params: 118,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "func_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sub class 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
